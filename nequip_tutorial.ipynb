{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-choung/Research_utility/blob/main/nequip_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFpAi8g9XmUU"
      },
      "source": [
        "# Molecular Dynamics with NequIP\n",
        "\n",
        "### Authors: Simon Batzner, Albert Musaelian, Lixin Sun, Anders Johansson, Boris Kozinsky"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMnK_PtDZ32t"
      },
      "source": [
        "<img src=\"https://github.com/mir-group/nequip_mrs_tutorial/blob/master/nequip3.png?raw=true\" width=\"60%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6YiV6ShQWB2"
      },
      "source": [
        "## What is this?\n",
        "\n",
        "This is a Colab tutorial for NequIP, software for building extremely accurate Machine Learning Interatomic Potentials. The ideas are described in the paper below. We have released an open-source software with the goal of building NequIP potentials with a few simple commands, at the Github link below. This tutorial serves as a simple introduction into the NequIP code.\n",
        "\n",
        "The goal of NequIP is to be as simple as possible. You will never have to write a single line of Python, but instead you can train a network with one single command and you will be ready to run MD with it in LAMMPS or ASE.\n",
        "\n",
        "Paper: https://www.nature.com/articles/s41467-022-29939-5\n",
        "\n",
        "Code: https://github.com/mir-group/nequip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8gImqa_N_e1"
      },
      "source": [
        "## Contents\n",
        "\n",
        "This tutorial will teach you how to:\n",
        "\n",
        "* Train a model\n",
        "* Deploy the model intro production\n",
        "* Run MD with it in LAMMPS\n",
        "\n",
        "We will do all this in this Colab, including LAMMPS. Training + inference will take only about 10 minutes. Before you get started, however, you will have to compile LAMMPS which takes approximately 5 minutes. Once we have installed NequIP + LAMMPS, we're ready to get started.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYSB405TdZWF"
      },
      "source": [
        "## Before you begin üõë\n",
        "\n",
        "1. Save a copy of this colab in your own drive\n",
        "2. Run the first two code cells below to install NequIP and the Molecular Dynamics code LAMMPS\n",
        "\n",
        "## Now you're ready to get started :) ‚úÖ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPqnt-SAXyvL"
      },
      "source": [
        "### Turn on GPU\n",
        "\n",
        "Make sure Runtime --> Change runtime type is set to GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XTzJ0cj-jmS"
      },
      "source": [
        "%%capture\n",
        "# install wandb\n",
        "!pip install wandb\n",
        "# install nequip\n",
        "!git clone --depth 1 \"https://github.com/mir-group/nequip.git\"\n",
        "!pip install nequip/\n",
        "# fix colab imports\n",
        "import site\n",
        "site.main()\n",
        "# set to allow anonymous WandB\n",
        "import os\n",
        "os.environ[\"WANDB_ANONYMOUS\"] = \"must\"\n",
        "import numpy as np\n",
        "import torch\n",
        "from ase.io import read, write\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# compile lammps\n",
        "!git clone -b stable_29Sep2021_update2 --depth 1 https://github.com/lammps/lammps.git\n",
        "!wget \"https://github.com/mir-group/pair_nequip/archive/main.zip\"\n",
        "!unzip -q main.zip\n",
        "!rm main.zip\n",
        "!mv pair_nequip-main pair_nequip\n",
        "!cd pair_nequip && ./patch_lammps.sh ../lammps\n",
        "!pip install mkl mkl-include\n",
        "!cd lammps && mkdir -p build && cd build && cmake ../cmake -DCMAKE_PREFIX_PATH=`python -c 'import torch;print(torch.utils.cmake_prefix_path)'` && make -j4"
      ],
      "metadata": {
        "id": "4_pB9Q0w4JJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HDmxkn3z8_m"
      },
      "source": [
        "## 3 Steps:\n",
        "* Train: using a data set, train the neural network üß†\n",
        "* Deploy: convert the Python-based model into a stand-alone potential file for fast execution ‚ö°\n",
        "* Run: run Molecular Dynamics, Monte Carlo, Structural Minimization, ...  with it in LAMMPS üèÉ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OD71eeDz7dA"
      },
      "source": [
        "<img src=\"https://github.com/mir-group/nequip_mrs_tutorial/blob/master/all.png?raw=true\" width=\"60%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62aEgq6QYFIn"
      },
      "source": [
        "### Train a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELdBzH_8z4_2"
      },
      "source": [
        "<img src=\"https://github.com/mir-group/nequip_mrs_tutorial/blob/master/train.png?raw=true\" width=\"60%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX0QKkAauSZO"
      },
      "source": [
        "This tutorial is set up to use `wandb` in anonymous mode; when you use NequIP yourself you will be presented with a login prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KuOIippfVfd"
      },
      "source": [
        "Here, we will train a NequIP potential on the following system\n",
        "\n",
        "* Toluene\n",
        "* sampled at T=500K from AIMD\n",
        "* at CCSD(T) accuracy (gold standard of quantum chemistry)\n",
        "* Using 100 training configurations\n",
        "* The units of the reference data are in kcal/mol and A. If you're more familiar with eV, remember 1 kcal/mol is chemical accuracy and is approximately 43 meV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q_GyQfC0npt"
      },
      "source": [
        "Start a training run: this will print output to our console, but it is usually more convenient to view the results in a web interface called Weights and Biases. Click the link next to the rocket emoji to watch the run in the WandB interface üöÄ\n",
        "\n",
        "In WandB, watch the followingkeys:\n",
        "\n",
        "* Plot 1: validation_all_f_mae, training_all_f_mae\n",
        "* Plot 2: validation_e/N_mae, training_e/N_mae\n",
        "\n",
        "These are the validation/training error in all force components and the validation/training error in the potential energy, normalized by the number of atoms, respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc-i-KbA_2ly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57ab3681-6a19-4936-e15d-c69162361691"
      },
      "source": [
        "!rm -rf ./results\n",
        "!nequip-train nequip/configs/example.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20220421_184458-15v6ir4a\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexample-run-toluene\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/anony-moose-241577/toluene-example?apiKey=ac764047f8d823ddbaf6595787c738368ab9eefb\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anony-moose-241577/toluene-example/runs/15v6ir4a?apiKey=ac764047f8d823ddbaf6595787c738368ab9eefb\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Do NOT share these links with anyone. They can be used to claim your runs.\n",
            "Torch device: cuda\n",
            "Downloading http://quantum-machine.org/gdml/data/npz/toluene_ccsd_t.zip\n",
            "Processing...\n",
            "Loaded data: Batch(batch=[15000], cell=[1000, 3, 3], edge_cell_shift=[154352, 3], edge_index=[2, 154352], forces=[15000, 3], pbc=[1000, 3], pos=[15000, 3], ptr=[1001], total_energy=[1000, 1])\n",
            "Cached processed data to disk\n",
            "Done!\n",
            "Successfully loaded the data set of type NpzDataset(1000)...\n",
            "Replace string dataset_forces_rms to 30.621034622192383\n",
            "Replace string dataset_per_atom_total_energy_mean to -11319.556640625\n",
            "Atomic outputs are scaled by: [H, C: 30.621035], shifted by [H, C: -11319.556641].\n",
            "Replace string dataset_forces_rms to 30.621034622192383\n",
            "Initially outputs are globally scaled by: 30.621034622192383, total_energy are globally shifted by None.\n",
            "Successfully built the network...\n",
            "Number of weights: 154200\n",
            "! Starting training ...\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      0    10        0.845        0.834       0.0108           21           28         13.7         29.3         21.5         17.5         36.4           27         47.6         3.17\n",
            "      0    20         1.32          1.3       0.0151         24.8         34.9         15.9         34.9         25.4         21.4         45.8         33.6         55.5          3.7\n",
            "\n",
            "\n",
            "  Initialization     #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Initial Validation          0    4.909    0.005         1.06       0.0125         1.08         22.6         31.6         14.8         31.5         23.1         19.9         41.1         30.5         50.9         3.39\n",
            "Wall time: 4.909433859000046\n",
            "! Best model        0    1.076\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      1    10        0.656        0.645       0.0107         17.7         24.6         9.93         26.7         18.3           13         33.2         23.1         47.3         3.16\n",
            "      1    20        0.213        0.209      0.00392         10.2           14         6.31         14.6         10.4         8.44         18.4         13.4         28.7         1.91\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      1    10        0.344        0.343     0.000911         12.7         17.9          7.3         18.9         13.1         9.23         24.3         16.8         12.2        0.816\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train               1    7.677    0.005        0.599       0.0198        0.619         16.7         23.7         10.5         23.8         17.2         14.4         31.1         22.7         54.4         3.63\n",
            "! Validation          1    7.677    0.005        0.239     0.000403        0.239         10.9           15         6.92         15.5         11.2         8.71         19.8         14.3         8.16        0.544\n",
            "Wall time: 7.677747869000086\n",
            "! Best model        1    0.239\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      2    10        0.161        0.155      0.00566         9.32         12.1         7.28         11.6         9.46          8.8           15         11.9         34.4          2.3\n",
            "      2    20        0.136        0.136     0.000451          8.5         11.3         6.07         11.3         8.67         7.67         14.3           11         8.88        0.592\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      2    10        0.175        0.175     6.85e-05          9.6         12.8         6.05         13.7         9.85         7.33           17         12.2         3.25        0.216\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train               2    9.564    0.005        0.177        0.013        0.189          9.5         12.9         6.21         13.3         9.74         7.82         16.9         12.3           41         2.73\n",
            "! Validation          2    9.564    0.005        0.128     6.01e-05        0.128         8.17           11         5.47         11.3         8.36         7.04         14.2         10.6         3.04        0.203\n",
            "Wall time: 9.565131335000046\n",
            "! Best model        2    0.128\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      3    10       0.0816       0.0804      0.00124         6.59         8.68         4.58         8.89         6.73         5.74         11.1         8.43         16.1         1.07\n",
            "      3    20       0.0823       0.0793      0.00303         6.29         8.62          3.9         9.02         6.46         4.88         11.5         8.19         25.3         1.68\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      3    10        0.116        0.116     0.000143          7.5         10.4         4.64         10.8         7.71         5.77           14         9.87         4.77        0.318\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train               3   11.447    0.005        0.106      0.00182        0.108         7.32         9.98         4.91         10.1         7.49         6.35         12.9         9.65         17.4         1.16\n",
            "! Validation          3   11.447    0.005       0.0904     0.000103       0.0905          6.8         9.21         4.45         9.47         6.96          5.7           12         8.86         3.83        0.256\n",
            "Wall time: 11.447427431000051\n",
            "! Best model        3    0.091\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      4    10       0.0422       0.0403      0.00187         4.81         6.15         3.98         5.76         4.87         5.04          7.2         6.12         19.7         1.32\n",
            "      4    20        0.087       0.0868     0.000213          6.8         9.02         4.78         9.12         6.95         6.32         11.3         8.83         6.51        0.434\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      4    10       0.0911       0.0911     5.65e-05         6.62         9.24         4.36          9.2         6.78         5.43         12.2         8.83         2.87        0.191\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train               4   13.311    0.005       0.0771      0.00116       0.0782         6.27          8.5         4.33         8.48         6.41         5.56         10.9         8.25         12.5         0.83\n",
            "! Validation          4   13.311    0.005        0.072     4.65e-05        0.072         6.11         8.22         4.24         8.25         6.24          5.4         10.5         7.98         2.47        0.164\n",
            "Wall time: 13.311546233000058\n",
            "! Best model        4    0.072\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      5    10       0.0601         0.06     6.89e-05         5.27          7.5         4.17         6.54         5.35         5.56         9.23          7.4         3.51        0.234\n",
            "      5    20        0.042       0.0419     0.000116         4.69         6.27         3.06         6.54          4.8         3.95         8.14         6.05          4.7        0.314\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      5    10       0.0719       0.0719     2.79e-05         5.82         8.21         3.83         8.09         5.96         4.95         10.8         7.87         2.23        0.149\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train               5   15.178    0.005       0.0659     0.000331       0.0663         5.82         7.86         4.08         7.81         5.95         5.24         10.1         7.65         7.08        0.472\n",
            "! Validation          5   15.178    0.005        0.057     2.85e-05       0.0571         5.43         7.31         3.85         7.23         5.54         4.97         9.29         7.13         1.96         0.13\n",
            "Wall time: 15.179232106000086\n",
            "! Best model        5    0.057\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      6    10       0.0527       0.0524     0.000306         5.21         7.01         3.82         6.79          5.3         4.83         8.86         6.85            8        0.534\n",
            "      6    20       0.0362       0.0357      0.00054         4.38         5.78         3.31         5.61         4.46         4.17          7.2         5.68         10.5        0.702\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      6    10       0.0522       0.0522     2.09e-05         5.03         6.99         3.55         6.73         5.14          4.7         8.92         6.81         1.98        0.132\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train               6   17.059    0.005       0.0468     0.000348       0.0472         4.93         6.63         3.68         6.36         5.02         4.79         8.24         6.51         7.32        0.488\n",
            "! Validation          6   17.059    0.005       0.0429     2.43e-05       0.0429         4.77         6.34         3.58         6.13         4.85          4.7         7.81         6.25          1.8         0.12\n",
            "Wall time: 17.059933172\n",
            "! Best model        6    0.043\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      7    10       0.0385       0.0384     6.32e-05         4.45            6         3.73         5.27          4.5         4.65         7.24         5.95         3.24        0.216\n",
            "      7    20       0.0227       0.0227     2.49e-05         3.61         4.61         3.13         4.16         3.65         3.94         5.28         4.61          1.6        0.106\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      7    10       0.0341       0.0341     2.32e-05         4.16         5.65         3.23         5.23         4.23         4.41          6.8         5.61          1.8         0.12\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train               7   18.985    0.005       0.0292     7.58e-05       0.0293         3.97         5.23         3.29         4.75         4.02         4.26         6.16         5.21         2.95        0.197\n",
            "! Validation          7   18.985    0.005       0.0297     2.37e-05       0.0298         4.02         5.28         3.32         4.81         4.07         4.41         6.12         5.27         1.71        0.114\n",
            "Wall time: 18.986084903000005\n",
            "! Best model        7    0.030\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      8    10       0.0238       0.0237     0.000139         3.65         4.71         2.91         4.49          3.7         3.78          5.6         4.69         5.23        0.349\n",
            "      8    20       0.0176       0.0175     0.000102         3.18         4.05         2.68         3.75         3.22         3.36         4.72         4.04         4.59        0.306\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      8    10       0.0252       0.0252      2.9e-05         3.62         4.86         2.99         4.34         3.67         4.16         5.55         4.85         2.08        0.138\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train               8   20.873    0.005       0.0223     8.23e-05       0.0224         3.46         4.58         2.92         4.08          3.5         3.86         5.28         4.57         3.67        0.245\n",
            "! Validation          8   20.873    0.005       0.0231     2.76e-05       0.0231         3.52         4.66         3.06         4.05         3.55         4.13         5.19         4.66         1.89        0.126\n",
            "Wall time: 20.873907815000052\n",
            "! Best model        8    0.023\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      9    10       0.0163       0.0162     4.97e-05         2.96          3.9         2.34         3.67            3         3.17         4.59         3.88         3.21        0.214\n",
            "      9    20        0.015        0.015     1.35e-05         2.81         3.75         2.26         3.43         2.85         3.17         4.32         3.75         1.53        0.102\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      9    10       0.0217       0.0217     1.35e-05         3.34         4.51         2.84         3.91         3.38            4         5.03         4.52         1.42       0.0948\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train               9   22.737    0.005       0.0194      2.6e-05       0.0194         3.23         4.26         2.74         3.79         3.26         3.62         4.89         4.26         1.98        0.132\n",
            "! Validation          9   22.737    0.005       0.0201     1.81e-05       0.0201         3.26         4.34         2.88         3.69         3.29         3.94         4.75         4.35          1.5          0.1\n",
            "Wall time: 22.738104502000056\n",
            "! Best model        9    0.020\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     10    10        0.021        0.021     1.07e-05         3.34         4.44         3.14         3.57         3.35         4.09          4.8         4.45         1.01       0.0673\n",
            "     10    20       0.0203       0.0202     0.000116         3.32         4.36         2.93         3.76         3.35         4.02         4.71         4.36         4.69        0.313\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     10    10       0.0192       0.0192     8.94e-06         3.11         4.25         2.72         3.56         3.14          3.9         4.62         4.26         1.28       0.0852\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              10   24.613    0.005       0.0168     0.000117       0.0169         3.01         3.97         2.57         3.51         3.04          3.4         4.53         3.96         4.31        0.287\n",
            "! Validation         10   24.613    0.005       0.0182     1.53e-05       0.0182         3.09         4.13         2.74         3.49         3.12          3.8         4.48         4.14         1.41       0.0941\n",
            "Wall time: 24.613299532000042\n",
            "! Best model       10    0.018\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     11    10       0.0156       0.0155     7.66e-05         2.79         3.82          2.6         2.99          2.8         3.65            4         3.82         3.57        0.238\n",
            "     11    20       0.0135       0.0134     6.32e-05         2.87         3.55         2.35         3.48         2.91         2.86         4.19         3.53         3.37        0.225\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     11    10       0.0176       0.0176     1.05e-05         2.95         4.07         2.63         3.32         2.98          3.8         4.35         4.07          1.3       0.0865\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              11   26.469    0.005       0.0155     5.32e-05       0.0155          2.9         3.81         2.48         3.36         2.92         3.28         4.33         3.81         2.85         0.19\n",
            "! Validation         11   26.469    0.005       0.0168      1.6e-05       0.0169         2.96         3.97         2.64         3.34         2.99         3.68         4.28         3.98         1.42       0.0947\n",
            "Wall time: 26.469893366000065\n",
            "! Best model       11    0.017\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     12    10       0.0105       0.0105     1.02e-05         2.32         3.13          2.2         2.47         2.33         3.03         3.25         3.14         1.17       0.0777\n",
            "     12    20       0.0117       0.0117     7.69e-06         2.57         3.31         2.15         3.06          2.6         2.74         3.85          3.3        0.984       0.0656\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     12    10       0.0163       0.0162     9.27e-06          2.8          3.9         2.53         3.12         2.82          3.7         4.12         3.91          1.2       0.0802\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              12   28.305    0.005        0.014     1.86e-05        0.014         2.76         3.62         2.38         3.18         2.78         3.15         4.09         3.62         1.53        0.102\n",
            "! Validation         12   28.305    0.005       0.0157     1.54e-05       0.0157         2.85         3.83         2.56         3.19         2.87         3.58          4.1         3.84         1.39       0.0926\n",
            "Wall time: 28.306025061000014\n",
            "! Best model       12    0.016\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     13    10       0.0117       0.0116     9.24e-05         2.52          3.3         2.01          3.1         2.56         2.73         3.85         3.29         4.38        0.292\n",
            "     13    20       0.0161        0.016     0.000144         2.81         3.87         2.66         2.98         2.82         3.61         4.15         3.88         5.06        0.337\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     13    10       0.0153       0.0153     1.13e-05          2.7         3.79         2.46         2.98         2.72         3.63         3.96         3.79         1.22       0.0812\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              13   30.165    0.005       0.0133      4.4e-05       0.0133         2.68         3.53         2.33         3.08          2.7         3.09         3.97         3.53          2.5        0.167\n",
            "! Validation         13   30.165    0.005       0.0148     1.68e-05       0.0148         2.77         3.73         2.49         3.09         2.79          3.5         3.97         3.73         1.43       0.0952\n",
            "Wall time: 30.166207621000012\n",
            "! Best model       13    0.015\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     14    10      0.00902      0.00892     9.95e-05         2.18         2.89         1.86         2.54          2.2         2.54         3.25         2.89         4.53        0.302\n",
            "     14    20       0.0114       0.0114     1.34e-05         2.44         3.27          2.2         2.71         2.46         2.84         3.71         3.27         1.43       0.0952\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     14    10        0.014       0.0139     7.42e-06         2.58         3.62         2.37         2.82         2.59         3.52         3.72         3.62         1.08       0.0721\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              14   32.089    0.005       0.0122     5.21e-05       0.0123         2.57         3.38         2.25         2.93         2.59         2.98         3.79         3.39         2.74        0.182\n",
            "! Validation         14   32.089    0.005       0.0139      1.4e-05       0.0139         2.69         3.61         2.43         2.98          2.7         3.41         3.83         3.62         1.32       0.0879\n",
            "Wall time: 32.09026132300005\n",
            "! Best model       14    0.014\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     15    10       0.0132       0.0132     6.44e-06         2.86         3.52         2.31          3.5          2.9         2.86         4.16         3.51        0.962       0.0642\n",
            "     15    20       0.0104       0.0104     1.19e-05         2.41         3.12         2.09         2.78         2.43         2.61         3.61         3.11         1.41       0.0942\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     15    10       0.0131       0.0131     7.95e-06          2.5          3.5         2.31         2.71         2.51         3.42         3.59         3.51         1.08       0.0717\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              15   33.958    0.005       0.0117     3.57e-05       0.0117         2.53         3.31         2.21          2.9         2.55         2.91         3.71         3.31         2.18        0.145\n",
            "! Validation         15   33.958    0.005       0.0132     1.45e-05       0.0132         2.61         3.51         2.36          2.9         2.63         3.32         3.72         3.52         1.33       0.0887\n",
            "Wall time: 33.9586557450001\n",
            "! Best model       15    0.013\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     16    10      0.00939      0.00914     0.000251         2.23         2.93         1.94         2.56         2.25         2.59         3.27         2.93         7.21        0.481\n",
            "     16    20       0.0132       0.0132     2.56e-05         2.68         3.52         1.99         3.47         2.73         2.76         4.22         3.49         1.63        0.109\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     16    10        0.012        0.012     6.57e-06          2.4         3.35         2.24         2.59         2.41         3.31          3.4         3.35            1       0.0669\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              16   35.840    0.005       0.0109     8.29e-05        0.011         2.43         3.19         2.12         2.78         2.45         2.81         3.58          3.2         3.58        0.239\n",
            "! Validation         16   35.840    0.005       0.0124     1.35e-05       0.0124         2.54         3.41          2.3         2.81         2.55         3.23          3.6         3.42         1.29       0.0859\n",
            "Wall time: 35.84036574700008\n",
            "! Best model       16    0.012\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     17    10       0.0114       0.0114     2.31e-05         2.46         3.26         1.78         3.23         2.51         2.52         3.95         3.23         2.07        0.138\n",
            "     17    20       0.0112       0.0112     1.02e-05         2.39         3.23         2.34         2.44         2.39         3.14         3.34         3.24         1.28       0.0856\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     17    10       0.0111       0.0111     4.83e-06         2.33         3.23         2.16         2.52         2.34          3.2         3.27         3.23        0.909       0.0606\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              17   37.752    0.005       0.0106      5.8e-05       0.0107         2.42         3.16         2.13         2.75         2.44         2.81         3.51         3.16         2.93        0.196\n",
            "! Validation         17   37.752    0.005       0.0117     1.19e-05       0.0117         2.47         3.31         2.24         2.73         2.49         3.15         3.49         3.32         1.21       0.0809\n",
            "Wall time: 37.75251903000003\n",
            "! Best model       17    0.012\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     18    10      0.00834      0.00826     8.78e-05         2.17         2.78         1.93         2.45         2.19         2.47          3.1         2.79         4.29        0.286\n",
            "     18    20      0.00598      0.00587     0.000112         1.84         2.35         1.55         2.16         1.86         2.03         2.66         2.35         4.85        0.323\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     18    10       0.0103       0.0103     4.26e-06         2.23          3.1         2.08         2.39         2.24         3.09         3.11          3.1        0.875       0.0583\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              18   39.612    0.005      0.00892     4.96e-05      0.00897         2.19         2.89         1.95         2.47         2.21          2.6         3.19          2.9         2.82        0.188\n",
            "! Validation         18   39.612    0.005        0.011     1.12e-05        0.011          2.4         3.22         2.18         2.66         2.42         3.06         3.39         3.22         1.18       0.0784\n",
            "Wall time: 39.61328866000008\n",
            "! Best model       18    0.011\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     19    10       0.0103       0.0102     8.13e-05         2.31         3.09         2.22         2.41         2.31         2.84         3.36          3.1         4.07        0.271\n",
            "     19    20       0.0112        0.011     0.000182         2.37         3.21         2.19         2.57         2.38         2.95         3.48         3.22         6.14        0.409\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     19    10      0.00961      0.00961     3.12e-06         2.16            3         1.99         2.35         2.17         2.97         3.04            3        0.734        0.049\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              19   41.500    0.005      0.00855     4.89e-05       0.0086         2.16         2.83         1.91         2.44         2.18         2.55         3.12         2.84         2.66        0.177\n",
            "! Validation         19   41.500    0.005       0.0104     9.51e-06       0.0104         2.34         3.13         2.11         2.59         2.35         2.97          3.3         3.13         1.12       0.0744\n",
            "Wall time: 41.500908897000045\n",
            "! Best model       19    0.010\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     20    10       0.0082      0.00801     0.000191         2.13         2.74         1.63          2.7         2.17         2.17         3.27         2.72         6.28        0.419\n",
            "     20    20      0.00816      0.00815     9.73e-06         2.17         2.76         1.82         2.56         2.19         2.34         3.18         2.76         1.17       0.0781\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     20    10      0.00909      0.00909      3.3e-06         2.11         2.92         1.92         2.31         2.12         2.87         2.97         2.92        0.766        0.051\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              20   43.497    0.005      0.00911     7.48e-05      0.00918         2.24         2.92         1.91         2.62         2.26         2.53         3.32         2.92         3.19        0.213\n",
            "! Validation         20   43.497    0.005       0.0099     9.85e-06      0.00991         2.28         3.05         2.05         2.54          2.3         2.88         3.22         3.05          1.1       0.0735\n",
            "Wall time: 43.49986824700011\n",
            "! Best model       20    0.010\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     21    10      0.00577      0.00577      2.5e-06         1.76         2.33         1.47          2.1         1.78         1.95         2.69         2.32        0.625       0.0417\n",
            "     21    20       0.0061      0.00609     1.72e-05         1.74         2.39         1.59         1.92         1.75         2.18          2.6         2.39         1.77        0.118\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     21    10      0.00846      0.00846     3.08e-06         2.04         2.82         1.86         2.25         2.05         2.76         2.87         2.82        0.728       0.0485\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              21   45.430    0.005      0.00792     1.66e-05      0.00794         2.07         2.73         1.81         2.38         2.09          2.4         3.06         2.73         1.59        0.106\n",
            "! Validation         21   45.430    0.005      0.00939     9.08e-06       0.0094         2.22         2.97         1.99         2.48         2.24          2.8         3.14         2.97         1.06       0.0708\n",
            "Wall time: 45.430755127\n",
            "! Best model       21    0.009\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     22    10      0.00868      0.00868        3e-06         2.23         2.85         1.79         2.73         2.26         2.42         3.28         2.85        0.628       0.0419\n",
            "     22    20      0.00516      0.00514     2.82e-05         1.61         2.19         1.34         1.92         1.63         1.83         2.55         2.19         2.33        0.155\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     22    10      0.00806      0.00806     3.11e-06            2         2.75          1.8         2.23         2.02         2.68         2.83         2.75        0.706       0.0471\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              22   47.287    0.005      0.00742     1.54e-05      0.00744         2.01         2.64         1.75         2.29         2.02         2.35         2.93         2.64          1.5       0.0998\n",
            "! Validation         22   47.287    0.005      0.00898     8.45e-06      0.00899         2.17          2.9         1.94         2.43         2.18         2.73         3.08         2.91         1.04       0.0694\n",
            "Wall time: 47.288201242000014\n",
            "! Best model       22    0.009\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     23    10      0.00586      0.00573     0.000127         1.78         2.32         1.51          2.1          1.8         2.01         2.62         2.32         5.17        0.344\n",
            "     23    20      0.00587      0.00571     0.000158         1.67         2.31         1.51         1.87         1.69         2.12         2.52         2.32         5.75        0.384\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     23    10      0.00771      0.00771     3.15e-06         1.96         2.69         1.75          2.2         1.98         2.59         2.79         2.69        0.722       0.0481\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              23   49.159    0.005      0.00727     6.79e-05      0.00734         1.98         2.61         1.69          2.3            2         2.28         2.95         2.61         3.24        0.216\n",
            "! Validation         23   49.159    0.005      0.00861      8.1e-06      0.00862         2.12         2.84         1.89         2.39         2.14         2.67         3.03         2.85         1.02       0.0678\n",
            "Wall time: 49.15950938600008\n",
            "! Best model       23    0.009\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     24    10      0.00693      0.00688     4.63e-05         1.97         2.54         1.76         2.22         1.99         2.28         2.81         2.54            3          0.2\n",
            "     24    20      0.00871       0.0087     5.37e-06         2.11         2.86          1.8         2.46         2.13         2.41         3.29         2.85        0.969       0.0646\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     24    10      0.00746      0.00745     2.78e-06         1.93         2.64          1.7         2.19         1.94         2.52         2.78         2.65        0.688       0.0458\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              24   51.012    0.005      0.00732     7.88e-05       0.0074         1.99         2.62         1.71         2.32         2.01         2.28         2.96         2.62         3.43        0.229\n",
            "! Validation         24   51.012    0.005      0.00829     7.96e-06       0.0083         2.08         2.79         1.84         2.35          2.1         2.61         2.98         2.79         0.99        0.066\n",
            "Wall time: 51.013038677000054\n",
            "! Best model       24    0.008\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     25    10      0.00482      0.00482     7.25e-06         1.62         2.13         1.28         2.02         1.65          1.7         2.52         2.11        0.916        0.061\n",
            "     25    20      0.00647      0.00641     5.72e-05         1.88         2.45         1.49         2.32         1.91         2.02         2.86         2.44         3.38        0.226\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     25    10       0.0072       0.0072     2.67e-06          1.9          2.6         1.66         2.17         1.91         2.46         2.75          2.6        0.678       0.0452\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              25   52.901    0.005      0.00666     2.29e-05      0.00668         1.89          2.5         1.65         2.18         1.91         2.22         2.79          2.5         1.81        0.121\n",
            "! Validation         25   52.901    0.005      0.00801     7.84e-06      0.00802         2.04         2.74         1.81         2.31         2.06         2.56         2.93         2.75        0.972       0.0648\n",
            "Wall time: 52.901937503\n",
            "! Best model       25    0.008\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     26    10      0.00671      0.00671     1.47e-06         1.95         2.51         1.63          2.3         1.97         2.23         2.79         2.51        0.469       0.0312\n",
            "     26    20      0.00499      0.00499     1.55e-06         1.72         2.16         1.61         1.84         1.72         2.04          2.3         2.17        0.544       0.0363\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     26    10      0.00699      0.00699     2.77e-06         1.87         2.56         1.62         2.15         1.89          2.4         2.73         2.57        0.691        0.046\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              26   54.742    0.005      0.00638     2.98e-05      0.00641         1.86         2.45         1.59         2.16         1.88         2.15         2.75         2.45         2.01        0.134\n",
            "! Validation         26   54.742    0.005      0.00774     7.37e-06      0.00775         2.01         2.69         1.77         2.28         2.02         2.51         2.89          2.7        0.952       0.0635\n",
            "Wall time: 54.743214014000046\n",
            "! Best model       26    0.008\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     27    10      0.00775      0.00775     4.93e-06         2.13          2.7         1.82         2.49         2.16          2.4         2.99          2.7        0.741       0.0494\n",
            "     27    20       0.0065      0.00645     5.88e-05         1.86         2.46         1.66          2.1         1.88         2.18         2.74         2.46         3.47        0.231\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     27    10      0.00679      0.00679     2.55e-06         1.84         2.52         1.59         2.12         1.86         2.35         2.71         2.53        0.672       0.0448\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              27   56.615    0.005       0.0063     2.69e-05      0.00633         1.85         2.43         1.57         2.17         1.87         2.12         2.74         2.43         2.03        0.135\n",
            "! Validation         27   56.615    0.005      0.00751     7.41e-06      0.00751         1.97         2.65         1.74         2.25         1.99         2.46         2.85         2.66        0.942       0.0628\n",
            "Wall time: 56.61585862200002\n",
            "! Best model       27    0.008\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     28    10      0.00451       0.0045      4.4e-06         1.52         2.05          1.3         1.78         1.54         1.88         2.24         2.06        0.747       0.0498\n",
            "     28    20       0.0073      0.00728      1.9e-05         2.05         2.61          1.9         2.22         2.06         2.46         2.78         2.62         1.89        0.126\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     28    10      0.00665      0.00665     2.66e-06         1.82          2.5         1.56         2.13         1.84          2.3          2.7          2.5        0.684       0.0456\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              28   58.486    0.005      0.00607     2.36e-05       0.0061         1.81         2.39         1.51         2.15         1.83         2.05         2.72         2.38         1.91        0.127\n",
            "! Validation         28   58.486    0.005       0.0073     6.99e-06      0.00731         1.94         2.62         1.71         2.22         1.96         2.42         2.82         2.62        0.918       0.0612\n",
            "Wall time: 58.486415661000024\n",
            "! Best model       28    0.007\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     29    10      0.00729      0.00725     4.76e-05            2         2.61         1.57         2.49         2.03         2.01         3.15         2.58          3.1        0.207\n",
            "     29    20       0.0057      0.00569      1.7e-05          1.7         2.31         1.61         1.82         1.71         2.22          2.4         2.31         1.59        0.106\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     29    10       0.0065       0.0065     2.48e-06          1.8         2.47         1.53         2.11         1.82         2.25          2.7         2.47        0.669       0.0446\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              29   60.366    0.005      0.00609     3.25e-05      0.00612         1.82         2.39         1.53         2.14         1.84         2.05         2.72         2.39         2.16        0.144\n",
            "! Validation         29   60.366    0.005      0.00709     6.94e-06       0.0071         1.92         2.58         1.68         2.19         1.93         2.38         2.79         2.58         0.91       0.0606\n",
            "Wall time: 60.36682418800001\n",
            "! Best model       29    0.007\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     30    10      0.00684      0.00677      6.3e-05         1.83         2.52         1.69         2.01         1.85          2.3         2.75         2.53         3.23        0.215\n",
            "     30    20       0.0065      0.00646     4.04e-05         1.83         2.46         1.68         2.01         1.84         2.19         2.73         2.46         2.79        0.186\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     30    10      0.00634      0.00634     2.33e-06         1.77         2.44          1.5         2.09         1.79         2.21         2.68         2.44        0.644       0.0429\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              30   62.273    0.005       0.0057     0.000108       0.0058         1.74         2.31         1.49         2.04         1.76         2.01         2.61         2.31         4.27        0.285\n",
            "! Validation         30   62.273    0.005       0.0069     7.16e-06      0.00691         1.89         2.54         1.64         2.17         1.91         2.34         2.76         2.55        0.926       0.0617\n",
            "Wall time: 62.27406887900008\n",
            "! Best model       30    0.007\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     31    10      0.00726      0.00726     2.07e-06         2.04         2.61         1.94         2.15         2.05         2.55         2.68         2.61        0.544       0.0363\n",
            "     31    20      0.00638      0.00635     2.88e-05         1.99         2.44         1.79         2.22            2         2.22         2.67         2.44         2.44        0.163\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     31    10       0.0062       0.0062     2.35e-06         1.75         2.41         1.48         2.06         1.77         2.17         2.66         2.41        0.653       0.0435\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              31   64.174    0.005      0.00742      8.3e-05      0.00751         2.05         2.64         1.72         2.42         2.07         2.24         3.03         2.63         3.48        0.232\n",
            "! Validation         31   64.174    0.005      0.00674     6.65e-06      0.00674         1.87         2.51         1.62         2.14         1.88         2.31         2.73         2.52        0.894       0.0596\n",
            "Wall time: 64.17445836200011\n",
            "! Best model       31    0.007\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     32    10      0.00582      0.00561     0.000203         1.79         2.29          1.5         2.13         1.82         1.99          2.6         2.29         6.49        0.433\n",
            "     32    20      0.00895      0.00891     4.43e-05         2.29         2.89         1.96         2.67         2.32         2.46         3.31         2.89         2.97        0.198\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     32    10      0.00602      0.00602     2.76e-06         1.73         2.38         1.46         2.03         1.75         2.14         2.62         2.38        0.681       0.0454\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              32   66.029    0.005      0.00635     9.15e-05      0.00644         1.87         2.44          1.6         2.19         1.89         2.11         2.77         2.44         3.81        0.254\n",
            "! Validation         32   66.029    0.005      0.00658     6.18e-06      0.00659         1.85         2.48          1.6         2.12         1.86         2.28          2.7         2.49         0.86       0.0574\n",
            "Wall time: 66.031102078\n",
            "! Best model       32    0.007\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     33    10      0.00401        0.004     1.05e-05         1.43         1.94         1.11          1.8         1.46         1.51         2.33         1.92         1.44       0.0962\n",
            "     33    20      0.00445      0.00445     2.24e-06         1.62         2.04         1.52         1.74         1.63         1.93         2.17         2.05        0.603       0.0402\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     33    10      0.00588      0.00588     2.69e-06          1.7         2.35         1.44         2.01         1.72         2.11          2.6         2.35        0.681       0.0454\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              33   67.905    0.005      0.00705     1.57e-05      0.00706         1.97         2.57         1.62         2.38            2         2.12         3.01         2.56         1.52        0.101\n",
            "! Validation         33   67.905    0.005      0.00643     6.11e-06      0.00644         1.82         2.46         1.58          2.1         1.84         2.25         2.67         2.46        0.852       0.0568\n",
            "Wall time: 67.90562986900011\n",
            "! Best model       33    0.006\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     34    10      0.00784      0.00783     1.05e-05         2.05         2.71          1.7         2.45         2.07         2.28         3.13          2.7         1.22       0.0812\n",
            "     34    20      0.00691      0.00689      1.2e-05         1.96         2.54         1.94         1.99         1.97         2.52         2.57         2.54         1.52        0.101\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     34    10      0.00569      0.00568     2.53e-06         1.67         2.31          1.4         1.97         1.69         2.06         2.57         2.31        0.669       0.0446\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              34   69.783    0.005      0.00536     1.91e-05      0.00538         1.71         2.24         1.49         1.96         1.73            2         2.49         2.25         1.68        0.112\n",
            "! Validation         34   69.783    0.005       0.0063     6.09e-06       0.0063          1.8         2.43         1.56         2.08         1.82         2.22         2.65         2.43        0.852       0.0568\n",
            "Wall time: 69.78400769200005\n",
            "! Best model       34    0.006\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     35    10      0.00468      0.00466     1.85e-05         1.63         2.09         1.38         1.92         1.65         1.82         2.36         2.09         1.96         0.13\n",
            "     35    20      0.00681      0.00671     0.000105         1.91         2.51         1.44         2.44         1.94         1.93         3.04         2.48         4.59        0.306\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     35    10      0.00562      0.00562     2.81e-06         1.65          2.3         1.38         1.97         1.67         2.03         2.57          2.3        0.684       0.0456\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              35   71.667    0.005       0.0055     4.02e-05      0.00554         1.76         2.27         1.54         2.01         1.78         2.01         2.53         2.27         2.48        0.165\n",
            "! Validation         35   71.667    0.005      0.00618     5.78e-06      0.00618         1.78         2.41         1.54         2.06          1.8          2.2         2.62         2.41        0.829       0.0552\n",
            "Wall time: 71.66751581000005\n",
            "! Best model       35    0.006\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     36    10       0.0049      0.00486     3.97e-05         1.66         2.14         1.51         1.84         1.67         1.95         2.33         2.14         2.86        0.191\n",
            "     36    20      0.00481       0.0048     7.85e-06         1.56         2.12         1.28         1.88         1.58         1.81         2.43         2.12         1.09       0.0725\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     36    10      0.00548      0.00548      2.4e-06         1.63         2.27         1.35         1.95         1.65         1.99         2.55         2.27        0.659        0.044\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              36   73.641    0.005      0.00517     4.53e-05      0.00521          1.7          2.2         1.52         1.91         1.71            2         2.41         2.21         2.66        0.177\n",
            "! Validation         36   73.641    0.005      0.00605     5.92e-06      0.00606         1.76         2.38         1.53         2.04         1.78         2.17          2.6         2.39        0.837       0.0558\n",
            "Wall time: 73.64133458800006\n",
            "! Best model       36    0.006\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     37    10      0.00668      0.00665      2.6e-05         1.93          2.5         1.58         2.33         1.95         2.06         2.92         2.49         2.27        0.151\n",
            "     37    20      0.00379      0.00377     1.86e-05         1.47         1.88          1.3         1.67         1.49         1.59         2.16         1.88         1.94        0.129\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     37    10      0.00538      0.00538     2.45e-06         1.61         2.25         1.33         1.93         1.63         1.96         2.54         2.25        0.669       0.0446\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              37   75.502    0.005      0.00519      3.3e-05      0.00522          1.7         2.21         1.47         1.96         1.71         1.93         2.49         2.21         2.27        0.151\n",
            "! Validation         37   75.502    0.005      0.00592     5.86e-06      0.00593         1.74         2.36         1.51         2.02         1.76         2.15         2.58         2.36        0.833       0.0555\n",
            "Wall time: 75.50259061000008\n",
            "! Best model       37    0.006\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     38    10      0.00423      0.00406      0.00017         1.49         1.95          1.3         1.71          1.5          1.8         2.12         1.96         5.96        0.398\n",
            "     38    20      0.00269      0.00263     5.95e-05         1.24         1.57          1.2         1.29         1.24         1.49         1.65         1.57         3.53        0.235\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     38    10      0.00526      0.00526      2.5e-06          1.6         2.22         1.31         1.92         1.62         1.92         2.52         2.22        0.666       0.0444\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              38   77.358    0.005      0.00454     4.55e-05      0.00459         1.58         2.06         1.37         1.81         1.59         1.83          2.3         2.07         2.61        0.174\n",
            "! Validation         38   77.358    0.005      0.00579     5.52e-06       0.0058         1.72         2.33         1.49         1.99         1.74         2.12         2.55         2.34        0.806       0.0537\n",
            "Wall time: 77.35914015800006\n",
            "! Best model       38    0.006\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     39    10      0.00412      0.00405     7.16e-05         1.46         1.95         1.35         1.58         1.47          1.8         2.11         1.95         3.78        0.252\n",
            "     39    20       0.0057      0.00569     8.95e-06         1.78         2.31         1.61         1.97         1.79         2.14         2.49         2.31         1.14        0.076\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     39    10      0.00519      0.00518     2.48e-06         1.58          2.2         1.29         1.91          1.6          1.9         2.51          2.2        0.672       0.0448\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              39   79.220    0.005      0.00466     4.26e-05       0.0047         1.58         2.09         1.34         1.85          1.6          1.8         2.38         2.09         2.53        0.169\n",
            "! Validation         39   79.220    0.005      0.00568     5.48e-06      0.00569         1.71         2.31         1.47         1.97         1.72          2.1         2.53         2.31        0.803       0.0535\n",
            "Wall time: 79.22082824800009\n",
            "! Best model       39    0.006\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     40    10      0.00469      0.00466      3.4e-05         1.59         2.09         1.24         1.98         1.61         1.64         2.51         2.07         2.64        0.176\n",
            "     40    20      0.00392      0.00391     9.34e-06         1.48         1.91         1.39         1.58         1.48         1.82         2.02         1.92         1.19       0.0792\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     40    10      0.00509      0.00509      2.4e-06         1.57         2.18         1.28          1.9         1.59         1.87         2.49         2.18        0.666       0.0444\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              40   81.080    0.005      0.00469     1.95e-05      0.00471         1.59          2.1         1.35         1.86          1.6          1.8         2.39          2.1         1.75        0.116\n",
            "! Validation         40   81.080    0.005      0.00558     5.46e-06      0.00558         1.69         2.29         1.45         1.95          1.7         2.08          2.5         2.29        0.803       0.0535\n",
            "Wall time: 81.08109480900009\n",
            "! Best model       40    0.006\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     41    10      0.00289      0.00289     3.12e-06         1.26         1.64         1.12         1.42         1.27         1.51         1.78         1.65        0.766        0.051\n",
            "     41    20      0.00496      0.00493     3.04e-05         1.72         2.15         1.46         2.01         1.74         1.83         2.47         2.15         2.49        0.166\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     41    10      0.00499      0.00499     2.32e-06         1.55         2.16         1.26         1.89         1.57         1.85         2.48         2.16        0.659        0.044\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              41   82.949    0.005      0.00437     2.38e-05      0.00439         1.54         2.02         1.35         1.76         1.56         1.79         2.26         2.03         1.87        0.125\n",
            "! Validation         41   82.949    0.005      0.00548     5.47e-06      0.00549         1.67         2.27         1.44         1.94         1.69         2.06         2.49         2.27        0.805       0.0536\n",
            "Wall time: 82.9498740570001\n",
            "! Best model       41    0.005\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     42    10      0.00351      0.00351     3.53e-06         1.35         1.81         1.06         1.68         1.37         1.48         2.13         1.81        0.816       0.0544\n",
            "     42    20      0.00567      0.00567     4.33e-06          1.8         2.31         1.54          2.1         1.82         1.93         2.67          2.3        0.697       0.0465\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     42    10      0.00491       0.0049     2.19e-06         1.54         2.14         1.24         1.89         1.56         1.81         2.47         2.14        0.641       0.0427\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              42   84.802    0.005      0.00481     3.26e-05      0.00484         1.62         2.12         1.32         1.97         1.64         1.74         2.49         2.11         2.25         0.15\n",
            "! Validation         42   84.802    0.005      0.00538     5.37e-06      0.00539         1.66         2.25         1.42         1.93         1.67         2.03         2.47         2.25        0.798       0.0532\n",
            "Wall time: 84.80279701500001\n",
            "! Best model       42    0.005\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     43    10       0.0052       0.0052      1.1e-06          1.7         2.21         1.57         1.85         1.71         1.94         2.48         2.21        0.431       0.0288\n",
            "     43    20      0.00359      0.00354     5.79e-05         1.39         1.82         1.26         1.54          1.4         1.71         1.94         1.82         3.44        0.229\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     43    10      0.00481      0.00481     2.23e-06         1.52         2.12         1.22         1.87         1.55         1.79         2.45         2.12        0.644       0.0429\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              43   86.664    0.005      0.00514     1.64e-05      0.00515         1.68         2.19         1.38         2.03          1.7         1.81         2.57         2.19         1.52        0.102\n",
            "! Validation         43   86.664    0.005      0.00529     5.22e-06      0.00529         1.64         2.23         1.41         1.91         1.66         2.01         2.45         2.23        0.787       0.0525\n",
            "Wall time: 86.66497464600002\n",
            "! Best model       43    0.005\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     44    10      0.00318      0.00312      6.4e-05         1.32         1.71         1.21         1.43         1.32         1.61         1.82         1.71         3.65        0.243\n",
            "     44    20      0.00451       0.0045     5.17e-06         1.61         2.05         1.42         1.83         1.62         1.84         2.27         2.06        0.875       0.0583\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     44    10      0.00472      0.00472     2.18e-06         1.51          2.1         1.21         1.85         1.53         1.77         2.43          2.1        0.637       0.0425\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              44   88.518    0.005      0.00447     4.55e-05      0.00452         1.56         2.05         1.36         1.79         1.58          1.8          2.3         2.05         2.79        0.186\n",
            "! Validation         44   88.518    0.005       0.0052     5.13e-06       0.0052         1.63         2.21         1.39         1.89         1.64         1.99         2.43         2.21        0.777       0.0518\n",
            "Wall time: 88.51849123400007\n",
            "! Best model       44    0.005\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     45    10      0.00373      0.00371     1.46e-05         1.39         1.87         1.17         1.65         1.41         1.57         2.15         1.86         1.66         0.11\n",
            "     45    20      0.00381      0.00381     1.48e-06          1.5         1.89         1.24          1.8         1.52         1.56         2.21         1.88        0.438       0.0292\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     45    10      0.00462      0.00462     2.25e-06         1.49         2.08          1.2         1.83         1.52         1.74         2.41         2.08        0.637       0.0425\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              45   90.362    0.005      0.00438        5e-05      0.00443         1.57         2.03         1.33         1.84         1.58         1.74         2.31         2.02          2.4         0.16\n",
            "! Validation         45   90.362    0.005       0.0051     4.91e-06      0.00511         1.61         2.19         1.38         1.88         1.63         1.97         2.41         2.19        0.757       0.0505\n",
            "Wall time: 90.362801117\n",
            "! Best model       45    0.005\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     46    10      0.00432      0.00428     3.33e-05         1.52            2         1.32         1.73         1.53         1.72         2.28            2         2.56        0.171\n",
            "     46    20      0.00283      0.00274     9.36e-05          1.2          1.6         1.19         1.21          1.2         1.63         1.57          1.6         4.43        0.295\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     46    10      0.00456      0.00456     2.32e-06         1.48         2.07         1.19         1.82         1.51         1.73          2.4         2.06        0.641       0.0427\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              46   92.278    0.005      0.00402      5.7e-05      0.00408         1.49         1.94         1.28         1.74         1.51         1.69          2.2         1.94         2.94        0.196\n",
            "! Validation         46   92.278    0.005      0.00502     4.74e-06      0.00502          1.6         2.17         1.37         1.86         1.62         1.95         2.39         2.17        0.742       0.0495\n",
            "Wall time: 92.2791573180001\n",
            "! Best model       46    0.005\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     47    10      0.00323      0.00314     9.22e-05         1.29         1.71         1.05         1.56         1.31          1.5         1.93         1.72         4.34         0.29\n",
            "     47    20      0.00476      0.00468     8.42e-05         1.65         2.09         1.35         1.99         1.67         1.79         2.39         2.09         4.18        0.279\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     47    10      0.00449      0.00449     2.26e-06         1.47         2.05         1.17         1.81         1.49          1.7         2.39         2.05        0.625       0.0417\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              47   94.135    0.005      0.00365     3.66e-05      0.00368         1.41         1.85          1.2         1.64         1.42          1.6          2.1         1.85         2.42        0.161\n",
            "! Validation         47   94.135    0.005      0.00493     4.71e-06      0.00493         1.58         2.15         1.35         1.85          1.6         1.93         2.38         2.15        0.739       0.0493\n",
            "Wall time: 94.13604876200009\n",
            "! Best model       47    0.005\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     48    10      0.00286      0.00285     2.68e-06         1.24         1.64         1.05         1.45         1.25         1.47          1.8         1.64        0.419       0.0279\n",
            "     48    20      0.00368      0.00363     4.85e-05         1.46         1.85         1.36         1.56         1.46         1.68         2.02         1.85         3.14         0.21\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     48    10      0.00442      0.00442     2.07e-06         1.46         2.04         1.16         1.81         1.48         1.68         2.38         2.03        0.609       0.0406\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              48   95.996    0.005      0.00409      2.7e-05      0.00411         1.49         1.96         1.28         1.74         1.51         1.69         2.23         1.96         1.86        0.124\n",
            "! Validation         48   95.996    0.005      0.00483     4.64e-06      0.00483         1.57         2.13         1.34         1.83         1.58         1.91         2.35         2.13        0.732       0.0488\n",
            "Wall time: 95.99642051600006\n",
            "! Best model       48    0.005\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     49    10      0.00507      0.00505     2.15e-05         1.77         2.18         1.63         1.94         1.78         1.95         2.41         2.18         2.06        0.137\n",
            "     49    20      0.00312      0.00312     2.27e-06         1.36         1.71         1.37         1.35         1.36         1.78         1.62          1.7        0.669       0.0446\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     49    10      0.00438      0.00438     1.88e-06         1.46         2.03         1.16          1.8         1.48         1.67         2.37         2.02        0.597       0.0398\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              49   97.862    0.005      0.00457     2.01e-05      0.00459          1.6         2.07         1.38         1.86         1.62         1.79         2.35         2.07         1.65         0.11\n",
            "! Validation         49   97.862    0.005      0.00474     4.75e-06      0.00474         1.55         2.11         1.32         1.81         1.57         1.89         2.33         2.11        0.744       0.0496\n",
            "Wall time: 97.8627947110001\n",
            "! Best model       49    0.005\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     50    10      0.00552       0.0053     0.000229         1.72         2.23         1.47         2.01         1.74         1.84          2.6         2.22         6.85        0.456\n",
            "     50    20      0.00565      0.00564     5.87e-06         1.78          2.3          1.6         1.99         1.79         2.01         2.59          2.3         1.03       0.0688\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     50    10      0.00427      0.00427     1.75e-06         1.44            2         1.14         1.78         1.46         1.64         2.34         1.99        0.578       0.0385\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              50   99.713    0.005      0.00409     5.56e-05      0.00414          1.5         1.96          1.3         1.72         1.51          1.7         2.22         1.96          2.9        0.193\n",
            "! Validation         50   99.713    0.005      0.00465      4.7e-06      0.00465         1.54         2.09         1.31          1.8         1.55         1.86         2.32         2.09        0.737       0.0491\n",
            "Wall time: 99.71411086300009\n",
            "! Best model       50    0.005\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     51    10      0.00392      0.00392     2.79e-06         1.42         1.92         1.21         1.66         1.43          1.6         2.22         1.91        0.728       0.0485\n",
            "     51    20      0.00444      0.00442     2.18e-05         1.64         2.04         1.64         1.63         1.64         2.04         2.03         2.04         2.08        0.139\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     51    10      0.00417      0.00417     1.73e-06         1.42         1.98         1.12         1.76         1.44         1.62         2.32         1.97        0.569       0.0379\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              51  101.562    0.005      0.00435     6.51e-05      0.00441         1.52         2.02         1.27         1.82         1.54         1.66         2.36         2.01         3.18        0.212\n",
            "! Validation         51  101.562    0.005      0.00456     4.49e-06      0.00456         1.52         2.07         1.29         1.78         1.54         1.85          2.3         2.07        0.718       0.0479\n",
            "Wall time: 101.56239180900002\n",
            "! Best model       51    0.005\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     52    10      0.00447      0.00432     0.000151         1.59         2.01         1.37         1.84          1.6         1.69         2.33         2.01          5.6        0.373\n",
            "     52    20      0.00435      0.00435     1.06e-06         1.61         2.02         1.26         2.01         1.64         1.65         2.37         2.01        0.409       0.0273\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     52    10      0.00409      0.00409     1.72e-06         1.41         1.96         1.11         1.74         1.43         1.61         2.29         1.95        0.569       0.0379\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              52  103.458    0.005       0.0047     2.96e-05      0.00473         1.62          2.1         1.34         1.93         1.64         1.72         2.46         2.09         2.06        0.137\n",
            "! Validation         52  103.458    0.005      0.00448     4.48e-06      0.00449         1.51         2.05         1.28         1.77         1.52         1.83         2.28         2.05        0.714       0.0476\n",
            "Wall time: 103.45836642400002\n",
            "! Best model       52    0.004\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     53    10      0.00479      0.00477     2.29e-05         1.67         2.11         1.34         2.06          1.7         1.71          2.5          2.1         2.13        0.142\n",
            "     53    20       0.0061      0.00609     8.55e-06         1.83         2.39         1.22         2.51         1.87         1.66         3.01         2.34         1.06       0.0708\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     53    10      0.00403      0.00403     1.84e-06          1.4         1.94          1.1         1.74         1.42         1.59         2.29         1.94        0.569       0.0379\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              53  105.344    0.005      0.00433     1.97e-05      0.00435         1.56         2.02          1.3         1.84         1.57         1.68         2.34         2.01         1.65         0.11\n",
            "! Validation         53  105.344    0.005      0.00441     4.19e-06      0.00442          1.5         2.03         1.27         1.76         1.51         1.81         2.26         2.04        0.692       0.0462\n",
            "Wall time: 105.34508968400007\n",
            "! Best model       53    0.004\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     54    10       0.0047      0.00467     2.96e-05         1.61         2.09         1.45          1.8         1.63         1.94         2.25          2.1         2.33        0.156\n",
            "     54    20      0.00423      0.00415     7.51e-05         1.58         1.97         1.31          1.9          1.6         1.63          2.3         1.97         3.94        0.263\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     54    10      0.00397      0.00397     1.73e-06         1.38         1.93         1.09         1.72          1.4         1.58         2.26         1.92        0.569       0.0379\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              54  107.230    0.005      0.00451     5.77e-05      0.00457         1.58         2.06         1.35         1.85          1.6         1.74         2.37         2.05         3.03        0.202\n",
            "! Validation         54  107.230    0.005      0.00434     4.33e-06      0.00435         1.48         2.02         1.26         1.74          1.5          1.8         2.25         2.02        0.699       0.0466\n",
            "Wall time: 107.230849347\n",
            "! Best model       54    0.004\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     55    10      0.00369      0.00367     2.04e-05         1.41         1.86         1.25          1.6         1.42         1.62         2.09         1.86         1.98        0.132\n",
            "     55    20      0.00611      0.00611     4.95e-06         1.81         2.39         1.28         2.42         1.85          1.7         2.99         2.35        0.931       0.0621\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     55    10      0.00388      0.00388     1.75e-06         1.37         1.91         1.08          1.7         1.39         1.56         2.24          1.9        0.556       0.0371\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              55  109.119    0.005      0.00374     1.77e-05      0.00376         1.44         1.87          1.2         1.71         1.46         1.58         2.16         1.87         1.56        0.104\n",
            "! Validation         55  109.119    0.005      0.00427     4.05e-06      0.00427         1.47            2         1.25         1.73         1.49         1.78         2.23            2        0.676        0.045\n",
            "Wall time: 109.11934819700002\n",
            "! Best model       55    0.004\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     56    10      0.00494      0.00488     6.04e-05         1.57         2.14         1.16         2.04          1.6         1.52         2.68          2.1         3.53        0.235\n",
            "     56    20      0.00484      0.00477     6.96e-05         1.67         2.12         1.38            2         1.69         1.72         2.49         2.11         3.79        0.253\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     56    10      0.00382      0.00381      1.6e-06         1.36         1.89         1.07         1.69         1.38         1.54         2.22         1.88        0.541        0.036\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              56  110.960    0.005      0.00414     4.82e-05      0.00419         1.51         1.97         1.25         1.82         1.53         1.63          2.3         1.96         2.57        0.171\n",
            "! Validation         56  110.960    0.005      0.00419     4.12e-06      0.00419         1.46         1.98         1.23         1.71         1.47         1.76         2.21         1.98         0.68       0.0453\n",
            "Wall time: 110.96038986400004\n",
            "! Best model       56    0.004\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     57    10      0.00317      0.00316     2.66e-06          1.3         1.72         1.04         1.59         1.32         1.31         2.09          1.7        0.722       0.0481\n",
            "     57    20      0.00313      0.00313     1.65e-06         1.36         1.71         1.18         1.56         1.37         1.45         1.97         1.71        0.512       0.0342\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     57    10      0.00374      0.00374     1.66e-06         1.35         1.87         1.06         1.68         1.37         1.53          2.2         1.86        0.534       0.0356\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              57  112.801    0.005      0.00349     4.12e-05      0.00353         1.39         1.81         1.16         1.65          1.4         1.51          2.1          1.8         2.53        0.169\n",
            "! Validation         57  112.801    0.005      0.00412     3.88e-06      0.00412         1.44         1.96         1.22          1.7         1.46         1.74         2.19         1.97        0.662       0.0441\n",
            "Wall time: 112.80134819500006\n",
            "! Best model       57    0.004\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     58    10      0.00382      0.00377     5.05e-05          1.5         1.88         1.39         1.62          1.5         1.72         2.05         1.88         3.21        0.214\n",
            "     58    20      0.00257      0.00256     9.65e-06         1.21         1.55        0.931         1.54         1.23         1.22         1.85         1.54         1.38       0.0923\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     58    10      0.00368      0.00368     1.71e-06         1.34         1.86         1.05         1.67         1.36         1.51         2.19         1.85        0.522       0.0348\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              58  114.654    0.005      0.00337     3.33e-05       0.0034         1.37         1.78         1.18         1.59         1.39         1.55         2.01         1.78         2.21        0.147\n",
            "! Validation         58  114.654    0.005      0.00404     3.71e-06      0.00405         1.43         1.95         1.21         1.69         1.45         1.72         2.17         1.95        0.642       0.0428\n",
            "Wall time: 114.655148048\n",
            "! Best model       58    0.004\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     59    10      0.00265      0.00265     1.29e-06         1.18         1.58        0.939         1.46          1.2         1.25         1.88         1.57          0.4       0.0267\n",
            "     59    20      0.00313      0.00287     0.000255         1.28         1.64         1.17         1.41         1.29         1.46         1.83         1.64         7.33        0.489\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     59    10      0.00362      0.00362     1.32e-06         1.33         1.84         1.04         1.66         1.35         1.48         2.18         1.83        0.488       0.0325\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              59  116.529    0.005      0.00327     5.62e-05      0.00332         1.35         1.75         1.18         1.54         1.36         1.53         1.98         1.75         2.77        0.184\n",
            "! Validation         59  116.529    0.005      0.00396     3.88e-06      0.00397         1.42         1.93         1.19         1.67         1.43          1.7         2.16         1.93        0.653       0.0435\n",
            "Wall time: 116.52967239300006\n",
            "! Best model       59    0.004\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     60    10      0.00235       0.0023     4.74e-05         1.14         1.47        0.903          1.4         1.15         1.14         1.77         1.45         3.16        0.211\n",
            "     60    20      0.00298      0.00296      1.1e-05         1.26         1.67         1.19         1.34         1.27          1.5         1.84         1.67         1.43       0.0956\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     60    10      0.00358      0.00358     1.45e-06         1.32         1.83         1.03         1.66         1.34         1.47         2.17         1.82        0.494       0.0329\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              60  118.404    0.005      0.00323      3.1e-05      0.00327         1.35         1.74         1.15         1.57         1.36         1.48            2         1.74         2.15        0.144\n",
            "! Validation         60  118.404    0.005       0.0039     3.66e-06       0.0039          1.4         1.91         1.18         1.66         1.42         1.68         2.15         1.91        0.632       0.0422\n",
            "Wall time: 118.40460215300004\n",
            "! Best model       60    0.004\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     61    10      0.00348      0.00346     1.24e-05         1.41          1.8         1.06         1.81         1.43         1.34         2.22         1.78         1.57        0.105\n",
            "     61    20      0.00385      0.00383     2.24e-05         1.39          1.9         1.06         1.76         1.41         1.43         2.32         1.87         2.17        0.144\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     61    10      0.00355      0.00354     1.48e-06         1.32         1.82         1.02         1.65         1.34         1.45         2.17         1.81        0.478       0.0319\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              61  120.272    0.005      0.00302     1.25e-05      0.00304         1.29         1.68          1.1         1.51          1.3         1.44         1.93         1.68         1.37       0.0914\n",
            "! Validation         61  120.272    0.005      0.00382      3.4e-06      0.00383         1.39         1.89         1.16         1.65         1.41         1.66         2.13         1.89        0.606       0.0404\n",
            "Wall time: 120.27325833900011\n",
            "! Best model       61    0.004\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     62    10       0.0035      0.00349     1.47e-05          1.4         1.81         1.24         1.58         1.41         1.58         2.03         1.81         1.71        0.114\n",
            "     62    20      0.00396      0.00395     1.03e-05         1.47         1.92            1            2          1.5         1.34         2.42         1.88         1.44        0.096\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     62    10       0.0035      0.00349     1.45e-06         1.31         1.81         1.02         1.64         1.33         1.44         2.15          1.8        0.478       0.0319\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              62  122.201    0.005      0.00333     1.82e-05      0.00335         1.35         1.77          1.1         1.62         1.36         1.45         2.07         1.76         1.68        0.112\n",
            "! Validation         62  122.201    0.005      0.00376     3.31e-06      0.00376         1.38         1.88         1.15         1.64         1.39         1.64         2.12         1.88        0.596       0.0397\n",
            "Wall time: 122.20211347100008\n",
            "! Best model       62    0.004\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     63    10      0.00512      0.00504     7.47e-05         1.66         2.17         1.36            2         1.68          1.9         2.45         2.18         3.85        0.257\n",
            "     63    20      0.00505      0.00503     2.07e-05         1.58         2.17         1.34         1.85          1.6         1.77         2.56         2.16         2.05        0.136\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     63    10      0.00344      0.00344     1.28e-06          1.3          1.8         1.01         1.63         1.32         1.43         2.14         1.78        0.453       0.0302\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              63  124.098    0.005       0.0042     3.84e-05      0.00424         1.53         1.98         1.28         1.81         1.55         1.66          2.3         1.98         2.39        0.159\n",
            "! Validation         63  124.098    0.005      0.00369      3.3e-06       0.0037         1.37         1.86         1.14         1.62         1.38         1.62          2.1         1.86        0.594       0.0396\n",
            "Wall time: 124.099255879\n",
            "! Best model       63    0.004\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     64    10      0.00278       0.0026     0.000181         1.17         1.56         1.32            1         1.16         1.67         1.43         1.55         6.15         0.41\n",
            "     64    20      0.00226      0.00226     4.06e-06          1.1         1.45        0.892         1.35         1.12         1.16         1.73         1.45        0.738       0.0492\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     64    10      0.00339      0.00339     1.42e-06         1.29         1.78            1         1.62         1.31         1.41         2.12         1.77        0.469       0.0312\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              64  125.954    0.005      0.00319     6.17e-05      0.00325         1.32         1.73         1.13         1.54         1.34         1.46         1.99         1.73         2.99          0.2\n",
            "! Validation         64  125.954    0.005      0.00364     3.18e-06      0.00364         1.35         1.85         1.13         1.61         1.37         1.61         2.09         1.85        0.584       0.0389\n",
            "Wall time: 125.954913067\n",
            "! Best model       64    0.004\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     65    10      0.00212      0.00211     3.94e-06         1.09         1.41        0.892         1.31          1.1         1.13         1.67          1.4        0.866       0.0577\n",
            "     65    20       0.0034      0.00339     7.08e-06         1.37         1.78         1.09         1.68         1.39         1.46         2.09         1.78         1.14       0.0758\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     65    10      0.00335      0.00335     1.29e-06         1.28         1.77         0.99         1.61          1.3          1.4         2.12         1.76        0.444       0.0296\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              65  127.820    0.005      0.00274     7.19e-06      0.00275         1.23          1.6         1.05         1.44         1.24         1.36         1.84          1.6        0.983       0.0656\n",
            "! Validation         65  127.820    0.005      0.00358     3.07e-06      0.00358         1.34         1.83         1.12          1.6         1.36         1.59         2.07         1.83        0.569        0.038\n",
            "Wall time: 127.8212512340001\n",
            "! Best model       65    0.004\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     66    10      0.00367      0.00365     2.33e-05         1.41         1.85         1.21         1.64         1.42         1.55         2.14         1.85         2.07        0.138\n",
            "     66    20       0.0038      0.00378     1.32e-05         1.44         1.88          1.1         1.82         1.46         1.46         2.27         1.87         1.53        0.102\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     66    10       0.0033       0.0033     1.19e-06         1.27         1.76        0.982          1.6         1.29         1.39          2.1         1.75        0.431       0.0287\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              66  129.684    0.005      0.00297     3.08e-05        0.003         1.28         1.67         1.06         1.53          1.3         1.38         1.95         1.66         2.07        0.138\n",
            "! Validation         66  129.684    0.005      0.00351     3.04e-06      0.00352         1.33         1.81          1.1         1.59         1.35         1.57         2.06         1.81        0.562       0.0375\n",
            "Wall time: 129.6847262220001\n",
            "! Best model       66    0.004\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     67    10      0.00329      0.00328     1.57e-05         1.31         1.75        0.965         1.71         1.34         1.31         2.15         1.73         1.77        0.118\n",
            "     67    20       0.0045       0.0045     3.27e-06         1.63         2.05         1.25         2.07         1.66         1.64         2.44         2.04        0.738       0.0492\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     67    10      0.00325      0.00324     1.08e-06         1.26         1.74         0.97         1.59         1.28         1.37         2.09         1.73        0.416       0.0277\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              67  131.538    0.005      0.00347     2.45e-05       0.0035         1.39          1.8         1.13         1.69         1.41         1.46         2.13          1.8         2.05        0.136\n",
            "! Validation         67  131.538    0.005      0.00346     3.02e-06      0.00346         1.32          1.8         1.09         1.58         1.34         1.55         2.05          1.8        0.558       0.0372\n",
            "Wall time: 131.5390687050001\n",
            "! Best model       67    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     68    10        0.006      0.00575     0.000246         1.74         2.32         1.33         2.21         1.77         1.57         2.96         2.26         7.18        0.479\n",
            "     68    20      0.00314      0.00313     1.62e-05         1.32         1.71         1.12         1.55         1.34         1.47         1.95         1.71         1.82        0.121\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     68    10       0.0032       0.0032     1.15e-06         1.25         1.73        0.963         1.59         1.27         1.36         2.07         1.72        0.419       0.0279\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              68  133.402    0.005      0.00418     7.23e-05      0.00425         1.51         1.98          1.2         1.86         1.53         1.55         2.38         1.96         3.29        0.219\n",
            "! Validation         68  133.402    0.005      0.00341     2.86e-06      0.00341         1.31         1.79         1.08         1.57         1.33         1.54         2.04         1.79        0.544       0.0363\n",
            "Wall time: 133.4023846020001\n",
            "! Best model       68    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     69    10      0.00417      0.00411     6.85e-05         1.56         1.96         1.32         1.84         1.58         1.66         2.26         1.96         3.79        0.253\n",
            "     69    20      0.00292      0.00289     2.35e-05         1.25         1.65         1.06         1.47         1.27         1.37         1.92         1.64         2.21        0.147\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     69    10      0.00314      0.00314     1.06e-06         1.24         1.72        0.961         1.56         1.26         1.36         2.05          1.7        0.403       0.0269\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              69  135.306    0.005      0.00361     2.76e-05      0.00363         1.42         1.84          1.1         1.77         1.44         1.43         2.22         1.82         2.07        0.138\n",
            "! Validation         69  135.306    0.005      0.00335     2.86e-06      0.00336          1.3         1.77         1.07         1.56         1.32         1.52         2.02         1.77        0.543       0.0362\n",
            "Wall time: 135.307081981\n",
            "! Best model       69    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     70    10      0.00397      0.00392     4.86e-05         1.43         1.92        0.892         2.05         1.47         1.15         2.52         1.84         3.17        0.211\n",
            "     70    20      0.00336      0.00332     3.47e-05         1.26         1.77        0.879          1.7         1.29         1.22         2.23         1.72         2.64        0.176\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     70    10      0.00309      0.00309     1.23e-06         1.23          1.7        0.956         1.55         1.25         1.35         2.03         1.69        0.416       0.0277\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              70  137.210    0.005      0.00296     3.54e-05      0.00299         1.26         1.66         1.02         1.54         1.28         1.34         1.97         1.66         2.44        0.163\n",
            "! Validation         70  137.210    0.005      0.00331     2.62e-06      0.00331         1.29         1.76         1.06         1.55         1.31         1.51         2.01         1.76        0.525        0.035\n",
            "Wall time: 137.21096574500007\n",
            "! Best model       70    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     71    10      0.00213      0.00212     2.84e-06         1.08         1.41         1.06         1.11         1.09         1.35         1.48         1.41        0.584        0.039\n",
            "     71    20      0.00305      0.00296     9.24e-05         1.27         1.66         1.07          1.5         1.29         1.37         1.95         1.66         4.35         0.29\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     71    10      0.00304      0.00304     9.26e-07         1.22         1.69        0.948         1.54         1.24         1.34         2.01         1.68        0.384       0.0256\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              71  139.138    0.005      0.00276     1.27e-05      0.00278         1.23         1.61         1.04         1.45         1.25         1.35         1.86         1.61         1.24       0.0829\n",
            "! Validation         71  139.138    0.005      0.00326     2.84e-06      0.00326         1.28         1.75         1.05         1.54          1.3          1.5            2         1.75        0.536       0.0357\n",
            "Wall time: 139.13910076800005\n",
            "! Best model       71    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     72    10      0.00244      0.00244     8.06e-07         1.17         1.51        0.945         1.43         1.19         1.21          1.8          1.5        0.397       0.0265\n",
            "     72    20       0.0036      0.00359     8.08e-06         1.41         1.83         1.33          1.5         1.41         1.68            2         1.84         1.12        0.075\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     72    10      0.00299      0.00299     1.01e-06         1.21         1.67         0.94         1.53         1.23         1.33            2         1.66        0.381       0.0254\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              72  141.035    0.005      0.00313     4.34e-05      0.00317         1.32         1.71         1.06         1.61         1.34         1.37         2.03          1.7          2.6        0.173\n",
            "! Validation         72  141.035    0.005      0.00321     2.61e-06      0.00321         1.27         1.73         1.04         1.53         1.29         1.48         1.98         1.73        0.515       0.0343\n",
            "Wall time: 141.03588439200007\n",
            "! Best model       72    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     73    10      0.00357      0.00356     9.72e-06         1.37         1.83         1.07         1.72         1.39         1.42          2.2         1.81         1.16       0.0773\n",
            "     73    20      0.00246      0.00237     8.83e-05         1.12         1.49        0.995         1.27         1.13          1.4         1.59          1.5         4.28        0.285\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     73    10      0.00293      0.00293     1.14e-06          1.2         1.66        0.927         1.51         1.22         1.31         1.98         1.65        0.397       0.0265\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              73  142.910    0.005      0.00328     1.74e-05       0.0033         1.33         1.75         1.05         1.65         1.35         1.36         2.12         1.74         1.53        0.102\n",
            "! Validation         73  142.910    0.005      0.00316      2.4e-06      0.00316         1.26         1.72         1.03         1.52         1.28         1.47         1.97         1.72        0.498       0.0332\n",
            "Wall time: 142.91094037800008\n",
            "! Best model       73    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     74    10      0.00436      0.00433     2.25e-05         1.57         2.02         1.12         2.07          1.6         1.37         2.56         1.97         2.11        0.141\n",
            "     74    20      0.00278      0.00278     5.33e-06         1.17         1.61        0.912         1.47         1.19         1.17            2         1.59         0.95       0.0633\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     74    10      0.00289      0.00289     9.61e-07         1.19         1.65        0.922          1.5         1.21         1.31         1.96         1.64        0.369       0.0246\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              74  144.812    0.005      0.00359     2.95e-05      0.00362         1.39         1.84         1.06         1.76         1.41         1.36         2.26         1.81         2.05        0.137\n",
            "! Validation         74  144.812    0.005      0.00312     2.45e-06      0.00313         1.25         1.71         1.02         1.51         1.27         1.46         1.96         1.71        0.497       0.0331\n",
            "Wall time: 144.81264917200008\n",
            "! Best model       74    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     75    10      0.00398      0.00396     1.61e-05          1.5         1.93        0.948         2.12         1.53         1.19         2.52         1.85         1.72        0.115\n",
            "     75    20      0.00349      0.00346     2.94e-05         1.29          1.8        0.913         1.71         1.31         1.16         2.33         1.74         2.48        0.166\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     75    10      0.00287      0.00287        1e-06         1.19         1.64        0.922         1.49         1.21          1.3         1.96         1.63        0.381       0.0254\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              75  146.752    0.005      0.00354     1.37e-05      0.00356         1.38         1.82         1.08         1.72          1.4         1.39         2.21          1.8         1.41       0.0939\n",
            "! Validation         75  146.752    0.005      0.00309     2.34e-06      0.00309         1.25          1.7         1.02          1.5         1.26         1.45         1.95          1.7        0.491       0.0327\n",
            "Wall time: 146.752411434\n",
            "! Best model       75    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     76    10      0.00258      0.00254     3.96e-05         1.15         1.54        0.885         1.45         1.17         1.12         1.91         1.52         2.81        0.187\n",
            "     76    20      0.00266      0.00264     1.34e-05         1.17         1.57        0.975         1.39         1.18         1.26         1.87         1.57         1.66         0.11\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     76    10      0.00283      0.00283     1.05e-06         1.18         1.63        0.913         1.48          1.2         1.29         1.94         1.62        0.387       0.0258\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              76  148.639    0.005      0.00266     4.59e-05      0.00271         1.21         1.58        0.996         1.46         1.23         1.28         1.86         1.57         2.51        0.168\n",
            "! Validation         76  148.639    0.005      0.00305     2.23e-06      0.00305         1.24         1.69         1.01         1.49         1.25         1.44         1.94         1.69        0.482       0.0322\n",
            "Wall time: 148.6396012470001\n",
            "! Best model       76    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     77    10      0.00232      0.00229     2.66e-05         1.14         1.47        0.949         1.36         1.15         1.18         1.73         1.46         2.36        0.157\n",
            "     77    20      0.00275      0.00273     1.21e-05         1.26          1.6         1.12         1.43         1.27          1.4          1.8          1.6         1.45       0.0969\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     77    10      0.00279      0.00279     1.04e-06         1.17         1.62         0.91         1.47         1.19         1.28         1.93         1.61        0.387       0.0258\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              77  150.544    0.005      0.00256     4.56e-05       0.0026         1.18         1.55        0.965         1.43          1.2         1.26         1.82         1.54          2.7         0.18\n",
            "! Validation         77  150.544    0.005      0.00299     2.12e-06      0.00299         1.23         1.68            1         1.48         1.24         1.42         1.92         1.67        0.471       0.0314\n",
            "Wall time: 150.54456765100008\n",
            "! Best model       77    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     78    10      0.00264      0.00261     2.66e-05          1.2         1.56        0.967         1.48         1.22         1.21         1.89         1.55         2.33        0.155\n",
            "     78    20      0.00363      0.00362     3.71e-06         1.44         1.84         1.19         1.72         1.46         1.46          2.2         1.83        0.847       0.0565\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     78    10      0.00277      0.00277     9.47e-07         1.17         1.61        0.905         1.47         1.19         1.28         1.92          1.6        0.363       0.0242\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              78  152.479    0.005      0.00273     2.22e-05      0.00275         1.22          1.6         1.02         1.46         1.24         1.32         1.87          1.6         1.83        0.122\n",
            "! Validation         78  152.479    0.005      0.00295     2.07e-06      0.00295         1.22         1.66        0.991         1.47         1.23         1.41         1.91         1.66        0.462       0.0308\n",
            "Wall time: 152.4796134390001\n",
            "! Best model       78    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     79    10      0.00166       0.0016     5.95e-05        0.934         1.23        0.847         1.03        0.941         1.05          1.4         1.23         3.51        0.234\n",
            "     79    20      0.00304      0.00289     0.000158         1.27         1.65         1.11         1.45         1.28         1.42         1.87         1.65         5.75        0.383\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     79    10      0.00274      0.00274     7.39e-07         1.16          1.6        0.901         1.46         1.18         1.27         1.91         1.59        0.322       0.0215\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              79  154.371    0.005      0.00317     9.52e-05      0.00326          1.3         1.72        0.997         1.65         1.32         1.28         2.12          1.7         3.82        0.255\n",
            "! Validation         79  154.371    0.005      0.00291     2.12e-06      0.00291         1.21         1.65        0.982         1.47         1.22          1.4          1.9         1.65        0.456       0.0304\n",
            "Wall time: 154.37139010700002\n",
            "! Best model       79    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     80    10      0.00338      0.00338     1.77e-06         1.34         1.78        0.938          1.8         1.37         1.25         2.24         1.74        0.547       0.0365\n",
            "     80    20      0.00567      0.00561     6.21e-05         1.81         2.29         1.43         2.24         1.83         1.75         2.79         2.27         3.51        0.234\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     80    10      0.00269      0.00269      6.6e-07         1.15         1.59        0.898         1.44         1.17         1.26         1.89         1.58        0.306       0.0204\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              80  156.258    0.005      0.00315     4.93e-05       0.0032         1.32         1.72         1.06          1.6         1.33         1.36         2.05         1.71         2.63        0.175\n",
            "! Validation         80  156.258    0.005      0.00288     2.11e-06      0.00288          1.2         1.64        0.975         1.46         1.22         1.39         1.89         1.64        0.453       0.0302\n",
            "Wall time: 156.258476212\n",
            "! Best model       80    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     81    10      0.00277      0.00277     3.39e-06         1.18         1.61        0.855         1.55          1.2         1.14         2.02         1.58        0.759       0.0506\n",
            "     81    20      0.00189      0.00185     3.57e-05         1.01         1.32         0.83         1.22         1.03         1.06         1.56         1.31         2.72        0.182\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     81    10      0.00266      0.00266     9.37e-07         1.15         1.58        0.895         1.44         1.17         1.25         1.88         1.57        0.363       0.0242\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              81  158.128    0.005      0.00271      1.6e-05      0.00272         1.23         1.59         1.01         1.47         1.24          1.3         1.87         1.59         1.54        0.102\n",
            "! Validation         81  158.128    0.005      0.00285     1.87e-06      0.00285         1.19         1.63        0.967         1.45         1.21         1.38         1.89         1.63        0.444       0.0296\n",
            "Wall time: 158.1290383050001\n",
            "! Best model       81    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     82    10       0.0016       0.0016     2.28e-06        0.953         1.22        0.931        0.979        0.955         1.21         1.24         1.22         0.65       0.0433\n",
            "     82    20      0.00361      0.00345     0.000161         1.39          1.8         1.13          1.7         1.41         1.38         2.18         1.78         5.81        0.387\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     82    10      0.00265      0.00265     6.06e-07         1.14         1.58         0.89         1.43         1.16         1.25         1.88         1.57        0.297       0.0198\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              82  159.992    0.005      0.00247     4.17e-05      0.00251         1.17         1.52        0.958         1.41         1.19         1.23          1.8         1.51         2.51        0.167\n",
            "! Validation         82  159.992    0.005      0.00281        2e-06      0.00281         1.18         1.62        0.957         1.45          1.2         1.36         1.87         1.62        0.439       0.0292\n",
            "Wall time: 159.99270586500006\n",
            "! Best model       82    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     83    10      0.00188      0.00188     1.18e-06        0.994         1.33        0.706         1.32         1.01        0.941         1.66          1.3        0.481       0.0321\n",
            "     83    20       0.0025      0.00248     1.54e-05         1.23         1.53         1.08          1.4         1.24          1.3         1.75         1.52         1.78        0.119\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     83    10      0.00261      0.00261     8.71e-07         1.14         1.57        0.884         1.43         1.16         1.24         1.87         1.55         0.35       0.0233\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              83  161.845    0.005      0.00232      2.6e-05      0.00235         1.14         1.48        0.897         1.41         1.15         1.15         1.78         1.46         1.87        0.125\n",
            "! Validation         83  161.845    0.005      0.00277     1.76e-06      0.00277         1.18         1.61        0.948         1.44         1.19         1.35         1.87         1.61        0.429       0.0286\n",
            "Wall time: 161.8459504650001\n",
            "! Best model       83    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     84    10      0.00321      0.00321     1.48e-06         1.31         1.74         1.06         1.59         1.32         1.35         2.09         1.72        0.531       0.0354\n",
            "     84    20      0.00262      0.00261     1.06e-06         1.18         1.57        0.786         1.63         1.21         1.02         2.02         1.52        0.409       0.0273\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     84    10      0.00259      0.00259     7.47e-07         1.13         1.56        0.876         1.42         1.15         1.23         1.86         1.55        0.322       0.0215\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              84  163.701    0.005      0.00242     5.84e-06      0.00242         1.16         1.51        0.918         1.43         1.17         1.18         1.81         1.49        0.859       0.0572\n",
            "! Validation         84  163.701    0.005      0.00273     1.73e-06      0.00273         1.17          1.6        0.938         1.43         1.18         1.33         1.85         1.59        0.419        0.028\n",
            "Wall time: 163.70178145700004\n",
            "! Best model       84    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     85    10      0.00175      0.00173     1.46e-05            1         1.28         0.81         1.22         1.02        0.982         1.54         1.26         1.76        0.117\n",
            "     85    20      0.00267      0.00267     7.54e-07         1.28         1.58         1.24         1.32         1.28         1.54         1.63         1.58        0.347       0.0231\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     85    10      0.00257      0.00257     7.69e-07         1.12         1.55        0.873         1.41         1.14         1.23         1.86         1.54        0.328       0.0219\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              85  165.568    0.005      0.00243     2.33e-05      0.00245         1.16         1.51        0.942         1.42         1.18         1.21         1.79          1.5          1.7        0.113\n",
            "! Validation         85  165.568    0.005       0.0027     1.64e-06       0.0027         1.16         1.59         0.93         1.42         1.17         1.33         1.85         1.59        0.412       0.0275\n",
            "Wall time: 165.56871055900012\n",
            "! Best model       85    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     86    10      0.00261       0.0026     7.67e-06         1.18         1.56         0.94         1.46          1.2         1.19          1.9         1.55         1.19       0.0796\n",
            "     86    20      0.00179      0.00176     2.64e-05        0.983         1.29        0.772         1.22        0.998         1.01         1.54         1.28         2.32        0.155\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     86    10      0.00254      0.00253      8.1e-07         1.12         1.54        0.864          1.4         1.13         1.21         1.85         1.53        0.338       0.0225\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              86  167.469    0.005      0.00235     1.63e-05      0.00237         1.14         1.49        0.928         1.39         1.16         1.19         1.77         1.48         1.57        0.104\n",
            "! Validation         86  167.469    0.005      0.00265     1.59e-06      0.00265         1.15         1.58        0.921         1.41         1.17         1.31         1.83         1.57        0.407       0.0271\n",
            "Wall time: 167.46941074400013\n",
            "! Best model       86    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     87    10      0.00219      0.00218     1.34e-05          1.1         1.43        0.934          1.3         1.12         1.19         1.66         1.43         1.63        0.109\n",
            "     87    20      0.00231      0.00228     2.86e-05         1.16         1.46          1.1         1.23         1.16         1.35         1.59         1.47         2.42        0.162\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     87    10      0.00251      0.00251      5.9e-07         1.11         1.53        0.863         1.39         1.13         1.21         1.83         1.52        0.281       0.0188\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              87  169.373    0.005      0.00232     1.18e-05      0.00233         1.12         1.48        0.906         1.37         1.14         1.16         1.77         1.46         1.33       0.0888\n",
            "! Validation         87  169.373    0.005      0.00262     1.63e-06      0.00262         1.14         1.57        0.913          1.4         1.16          1.3         1.82         1.56        0.397       0.0265\n",
            "Wall time: 169.3739456520001\n",
            "! Best model       87    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     88    10      0.00265      0.00264      1.4e-05         1.18         1.57            1         1.39         1.19         1.34         1.81         1.57         1.69        0.113\n",
            "     88    20      0.00369      0.00367     2.09e-05         1.48         1.86         1.25         1.75          1.5         1.55         2.15         1.85         1.89        0.126\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     88    10      0.00247      0.00247     7.52e-07          1.1         1.52         0.86         1.37         1.11         1.21         1.81         1.51        0.322       0.0215\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              88  171.231    0.005      0.00332     2.48e-05      0.00335         1.34         1.77         1.03         1.69         1.36         1.33         2.16         1.74         1.92        0.128\n",
            "! Validation         88  171.231    0.005      0.00259     1.51e-06      0.00259         1.13         1.56        0.906         1.39         1.15         1.29         1.81         1.55        0.394       0.0263\n",
            "Wall time: 171.23148935400002\n",
            "! Best model       88    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     89    10      0.00221      0.00219     2.39e-05         1.08         1.43        0.901         1.29         1.09         1.17         1.69         1.43         2.21        0.148\n",
            "     89    20      0.00163      0.00163     5.78e-07        0.959         1.24        0.701         1.25        0.977        0.918         1.52         1.22        0.272       0.0181\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     89    10      0.00246      0.00246     6.05e-07          1.1         1.52        0.852         1.37         1.11          1.2         1.81         1.51        0.278       0.0185\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              89  173.092    0.005      0.00222     1.55e-05      0.00224          1.1         1.44        0.891         1.34         1.12         1.15         1.72         1.44          1.5       0.0998\n",
            "! Validation         89  173.092    0.005      0.00255      1.5e-06      0.00255         1.12         1.55        0.897         1.39         1.14         1.28          1.8         1.54        0.387       0.0258\n",
            "Wall time: 173.09329226400007\n",
            "! Best model       89    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     90    10      0.00204      0.00204     1.13e-06         1.02         1.38         0.92         1.14         1.03         1.21         1.56         1.38        0.438       0.0292\n",
            "     90    20      0.00254      0.00253     1.05e-05         1.15         1.54        0.943         1.38         1.16         1.31         1.77         1.54         1.45       0.0969\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     90    10      0.00244      0.00244     6.37e-07         1.09         1.51        0.852         1.37         1.11          1.2         1.81          1.5        0.294       0.0196\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              90  175.046    0.005      0.00193     4.36e-06      0.00193         1.03         1.34        0.844         1.24         1.04          1.1         1.58         1.34        0.796       0.0531\n",
            "! Validation         90  175.046    0.005      0.00253     1.41e-06      0.00253         1.12         1.54        0.888         1.38         1.13         1.27          1.8         1.53        0.381       0.0254\n",
            "Wall time: 175.04704789100003\n",
            "! Best model       90    0.003\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     91    10      0.00123      0.00122     3.69e-06        0.822         1.07        0.621         1.05        0.836        0.783         1.32         1.05        0.856       0.0571\n",
            "     91    20      0.00225      0.00222     2.99e-05         1.14         1.44        0.983         1.32         1.15         1.19         1.68         1.44         2.46        0.164\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     91    10      0.00241      0.00241     5.26e-07         1.09          1.5        0.846         1.36          1.1         1.19          1.8         1.49        0.259       0.0173\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              91  176.914    0.005       0.0019     9.54e-06      0.00191         1.02         1.33        0.835         1.23         1.03         1.08         1.57         1.33         1.11        0.074\n",
            "! Validation         91  176.914    0.005       0.0025     1.45e-06       0.0025         1.11         1.53         0.88         1.37         1.13         1.26         1.79         1.52        0.379       0.0252\n",
            "Wall time: 176.91446040900007\n",
            "! Best model       91    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     92    10      0.00214      0.00207     6.95e-05         1.07         1.39        0.835         1.33         1.08         1.06         1.69         1.38         3.83        0.255\n",
            "     92    20      0.00271      0.00271     8.54e-06         1.24         1.59        0.929          1.6         1.27         1.24         1.92         1.58         1.23       0.0821\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     92    10      0.00238      0.00238     5.26e-07         1.08         1.49         0.84         1.35          1.1         1.18         1.79         1.48        0.256       0.0171\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              92  178.786    0.005      0.00195     2.12e-05      0.00197         1.03         1.35        0.776         1.31         1.04            1         1.66         1.33         1.75        0.116\n",
            "! Validation         92  178.786    0.005      0.00247     1.36e-06      0.00247          1.1         1.52        0.873         1.36         1.12         1.25         1.78         1.52        0.369       0.0246\n",
            "Wall time: 178.78672570100014\n",
            "! Best model       92    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     93    10        0.002      0.00192     8.34e-05         1.03         1.34        0.855         1.23         1.04         1.14         1.54         1.34         4.19        0.279\n",
            "     93    20      0.00168      0.00166     2.46e-05         0.92         1.25        0.753         1.11        0.931         1.08         1.41         1.25         2.27        0.151\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     93    10      0.00237      0.00237      6.2e-07         1.07         1.49        0.837         1.34         1.09         1.18         1.78         1.48          0.3         0.02\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              93  180.664    0.005      0.00209     3.56e-05      0.00212         1.07          1.4        0.867         1.31         1.09         1.12         1.66         1.39         2.45        0.163\n",
            "! Validation         93  180.664    0.005      0.00244     1.26e-06      0.00244          1.1         1.51        0.866         1.36         1.11         1.24         1.77         1.51        0.363       0.0242\n",
            "Wall time: 180.66503371200008\n",
            "! Best model       93    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     94    10       0.0019       0.0019     1.94e-06         1.04         1.33        0.841         1.28         1.06         1.03         1.62         1.32        0.569       0.0379\n",
            "     94    20      0.00342      0.00342     9.23e-07         1.27         1.79        0.815         1.79          1.3         1.13         2.33         1.73        0.406       0.0271\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     94    10      0.00233      0.00233     4.97e-07         1.07         1.48        0.836         1.33         1.08         1.17         1.76         1.47        0.259       0.0173\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              94  182.567    0.005      0.00204     1.77e-05      0.00206         1.05         1.38        0.824         1.31         1.07         1.06         1.68         1.37         1.63        0.109\n",
            "! Validation         94  182.567    0.005      0.00242     1.25e-06      0.00242         1.09         1.51         0.86         1.35         1.11         1.23         1.77          1.5        0.357       0.0238\n",
            "Wall time: 182.56732957700012\n",
            "! Best model       94    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     95    10      0.00319      0.00311     8.65e-05         1.29         1.71         1.07         1.55         1.31         1.33         2.05         1.69         4.25        0.283\n",
            "     95    20      0.00218      0.00215     3.03e-05         1.09         1.42        0.966         1.22         1.09         1.23         1.61         1.42          2.5        0.167\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     95    10      0.00232      0.00232      3.9e-07         1.06         1.47        0.833         1.33         1.08         1.17         1.76         1.46        0.222       0.0148\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              95  184.460    0.005      0.00243     3.61e-05      0.00247         1.15         1.51        0.962         1.37         1.17         1.24         1.77          1.5         2.31        0.154\n",
            "! Validation         95  184.460    0.005      0.00239      1.3e-06       0.0024         1.08          1.5        0.854         1.35          1.1         1.23         1.76         1.49        0.362       0.0241\n",
            "Wall time: 184.461078724\n",
            "! Best model       95    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     96    10      0.00335      0.00319     0.000157         1.35         1.73         1.13         1.59         1.36         1.42         2.03         1.72         5.75        0.383\n",
            "     96    20      0.00287      0.00284     3.59e-05          1.3         1.63         1.09         1.55         1.32         1.38         1.88         1.63         2.74        0.183\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     96    10      0.00229      0.00229     3.31e-07         1.06         1.47        0.828         1.32         1.08         1.16         1.75         1.46        0.219       0.0146\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              96  186.385    0.005      0.00235     6.21e-05      0.00241         1.13         1.48        0.914         1.39         1.15         1.18         1.77         1.47         3.08        0.206\n",
            "! Validation         96  186.385    0.005      0.00238     1.31e-06      0.00238         1.08         1.49        0.849         1.34          1.1         1.22         1.75         1.49         0.36        0.024\n",
            "Wall time: 186.3861286560001\n",
            "! Best model       96    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     97    10      0.00148      0.00146     2.15e-05        0.891         1.17        0.685         1.13        0.906        0.856         1.44         1.15         2.11        0.141\n",
            "     97    20      0.00139      0.00138     1.52e-05        0.874         1.14        0.753         1.01        0.883        0.934         1.33         1.13         1.77        0.118\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     97    10      0.00228      0.00228     4.07e-07         1.06         1.46         0.83         1.32         1.07         1.16         1.74         1.45        0.231       0.0154\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              97  188.260    0.005      0.00235     3.99e-05      0.00239         1.12         1.48        0.854         1.42         1.14         1.09         1.84         1.46         2.41        0.161\n",
            "! Validation         97  188.260    0.005      0.00235     1.22e-06      0.00235         1.07         1.49        0.845         1.33         1.09         1.21         1.75         1.48        0.349       0.0233\n",
            "Wall time: 188.26284789500016\n",
            "! Best model       97    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     98    10      0.00228      0.00227     1.25e-05          1.1         1.46        0.868         1.36         1.11         1.12         1.76         1.44         1.59        0.106\n",
            "     98    20      0.00334      0.00333     9.48e-06         1.41         1.77          1.1         1.77         1.43         1.43         2.09         1.76         1.36       0.0906\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     98    10      0.00226      0.00226      4.2e-07         1.05         1.46        0.828         1.31         1.07         1.16         1.73         1.45        0.231       0.0154\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              98  190.121    0.005      0.00186     2.28e-05      0.00189            1         1.32        0.797         1.24         1.02         1.04         1.58         1.31         1.79        0.119\n",
            "! Validation         98  190.121    0.005      0.00233     1.17e-06      0.00233         1.07         1.48         0.84         1.33         1.08         1.21         1.74         1.47        0.345        0.023\n",
            "Wall time: 190.12135159599995\n",
            "! Best model       98    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     99    10      0.00221       0.0022     1.72e-06         1.07         1.44        0.782          1.4         1.09         0.99         1.82          1.4        0.416       0.0277\n",
            "     99    20      0.00385      0.00385      1.6e-06         1.41          1.9        0.854         2.05         1.45          1.1         2.52         1.81        0.491       0.0327\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     99    10      0.00222      0.00222     3.52e-07         1.04         1.44        0.822         1.29         1.06         1.15         1.71         1.43        0.209        0.014\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              99  191.995    0.005      0.00255     6.45e-06      0.00256         1.17         1.55        0.931         1.44         1.19         1.21         1.86         1.53        0.996       0.0664\n",
            "! Validation         99  191.995    0.005       0.0023     1.18e-06      0.00231         1.06         1.47        0.835         1.32         1.08          1.2         1.73         1.46        0.346       0.0231\n",
            "Wall time: 191.99551739200012\n",
            "! Best model       99    0.002\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "    100    10       0.0016      0.00158     1.38e-05        0.968         1.22        0.766          1.2        0.982        0.961         1.46         1.21         1.68        0.112\n",
            "    100    20      0.00193      0.00192     2.37e-06         1.01         1.34        0.905         1.14         1.02         1.28         1.41         1.35        0.631       0.0421\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "    100    10      0.00219      0.00219     5.29e-07         1.03         1.43        0.818         1.28         1.05         1.14          1.7         1.42        0.272       0.0181\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train             100  193.854    0.005       0.0024     1.03e-05      0.00241         1.12          1.5        0.873          1.4         1.14         1.13         1.83         1.48         1.23        0.082\n",
            "! Validation        100  193.854    0.005      0.00228      1.1e-06      0.00228         1.06         1.46        0.831         1.31         1.07         1.19         1.72         1.46        0.337       0.0225\n",
            "Wall time: 193.85454514200012\n",
            "! Best model      100    0.002\n",
            "! Stop training: max epochs\n",
            "Wall time: 193.88583297900016\n",
            "Cumulative wall time: 193.88583297900016\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      LR ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         cumulative_wall ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        training_C_f_mae ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       training_C_f_rmse ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        training_H_f_mae ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       training_H_f_rmse ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        training_e/N_mae ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          training_e_mae ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          training_f_mae ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         training_f_rmse ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           training_loss ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss_e ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss_f ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    training_psavg_f_mae ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   training_psavg_f_rmse ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      validation_C_f_mae ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     validation_C_f_rmse ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      validation_H_f_mae ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     validation_H_f_rmse ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      validation_e/N_mae ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        validation_e_mae ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        validation_f_mae ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_f_rmse ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         validation_loss ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss_e ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss_f ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  validation_psavg_f_mae ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: validation_psavg_f_rmse ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    wall ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      LR 0.005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         cumulative_wall 193.85374\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   epoch 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        training_C_f_mae 1.40153\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       training_C_f_rmse 1.83484\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        training_H_f_mae 0.87265\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       training_H_f_rmse 1.12717\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        training_e/N_mae 0.08203\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          training_e_mae 1.23047\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          training_f_mae 1.11946\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         training_f_rmse 1.49956\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           training_loss 0.00241\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss_e 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         training_loss_f 0.0024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    training_psavg_f_mae 1.13709\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   training_psavg_f_rmse 1.481\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      validation_C_f_mae 1.3145\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     validation_C_f_rmse 1.71984\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      validation_H_f_mae 0.83148\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     validation_H_f_rmse 1.19447\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      validation_e/N_mae 0.02246\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        validation_e_mae 0.33687\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        validation_f_mae 1.05689\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_f_rmse 1.46331\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         validation_loss 0.00228\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss_e 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss_f 0.00228\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  validation_psavg_f_mae 1.07299\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: validation_psavg_f_rmse 1.45715\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    wall 193.85374\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mexample-run-toluene\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/anony-moose-241577/toluene-example/runs/15v6ir4a?apiKey=ac764047f8d823ddbaf6595787c738368ab9eefb\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220421_184458-15v6ir4a/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EwuQZLDO4Cr"
      },
      "source": [
        "We see that the model has converged to an energy accuarcy < 1meV/atom and a force accuracy of approx. 40 meV/A within 5 minutes and trained on only 100 samples. That should give us a good first potential! Note that these numbers will decrease significantly if you increase the training set size and the number of epochs to train."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJitSZgLYNNF"
      },
      "source": [
        "### Deploy the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo_kIpYV00as"
      },
      "source": [
        "<img src=\"https://github.com/mir-group/nequip_mrs_tutorial/blob/master/deploy.png?raw=true\" width=\"60%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VoeGtlA02KQ"
      },
      "source": [
        "We now convert the model to a potential file. This makes it independent of NequIP and we can use it any downstream application, such as LAMMPS."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3NJJgtDIDNc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5d86b6b-c649-4d46-e1aa-457b2e7ceb13"
      },
      "source": [
        "!nequip-deploy build --train-dir results/toluene/example-run-toluene toluene-deployed.pth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:root:Atomic outputs are scaled by: 1.0, shifted by 0.0.\n",
            "INFO:root:Compiled & optimized model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXpcE3oP0LyD"
      },
      "source": [
        "## Evaluate Test Error on all remaining frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wRKKCZ2PRl3"
      },
      "source": [
        "Before running inference, we'd like to know how well the model is doing on a hold-out test set. We run the nequip-evaluate command to compute the test error on all data that we didn't use for training or validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB54WSrN0PaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96734101-62b1-4b9a-8c23-1c5c1387fbd5"
      },
      "source": [
        "!nequip-evaluate --train-dir results/toluene/example-run-toluene --batch-size 50"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "WARNING: please note that models running on CUDA are usually nondeterministc and that this manifests in the final test errors; for a _more_ deterministic result, please use `--device cpu`\n",
            "Loading model... \n",
            "loaded model from training session\n",
            "Loading original dataset...\n",
            "Loaded dataset specified in config.yaml.\n",
            "Using origial training dataset (1000 frames) minus training (100 frames) and validation frames (50 frames), yielding a test set size of 850 frames.\n",
            "Starting...\n",
            "  0% 0/850 [00:00<?, ?it/s]\n",
            "\u001b[A\n",
            "  6% 50/850 [00:00<00:04, 198.25it/s]\n",
            " 12% 100/850 [00:00<00:07, 95.56it/s]\n",
            " 18% 150/850 [00:02<00:14, 46.79it/s]\n",
            " 24% 200/850 [00:04<00:17, 37.76it/s]\n",
            "\u001b[A\n",
            " 35% 300/850 [00:04<00:07, 76.45it/s]\n",
            "\u001b[A\n",
            " 47% 400/850 [00:04<00:03, 125.72it/s]\n",
            "\u001b[A\n",
            "\u001b[A\n",
            " 65% 550/850 [00:04<00:01, 217.01it/s]\n",
            "\u001b[A\n",
            "\u001b[A\n",
            " 82% 700/850 [00:04<00:00, 319.80it/s]\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "100% 850/850 [00:05<00:00, 167.55it/s]\n",
            "\n",
            "\n",
            "--- Final result: ---\n",
            "             0_f_mae =  0.796981           \n",
            "             1_f_mae =  1.318640           \n",
            "           all_f_mae =  1.057810           \n",
            "             e/N_mae =  0.022260           \n",
            "             0_f_mae =  0.796981           \n",
            "             1_f_mae =  1.318640           \n",
            "           all_f_mae =  1.057810           \n",
            "             e/N_mae =  0.022260           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQHrMMnsPaJO"
      },
      "source": [
        "Again, energy errors of < 1meV/atom (converted from kcal/mol to eV), and force errors of ~45 meV/A üéâ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4r5FBXaum9n"
      },
      "source": [
        "# LAMMPS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qIYIYyr1B4O"
      },
      "source": [
        "We are now in a position to run MD with our potential. Here, we will minimize the geometry of the toluene molecule we trained on from a perturbed initial state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UirNBTlJ1BNZ"
      },
      "source": [
        "<img src=\"https://github.com/mir-group/nequip_mrs_tutorial/blob/master/run.png?raw=true\" width=\"60%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQs0ijPhvAGb"
      },
      "source": [
        "Set up a simple LAMMPS input file\n",
        "\n",
        "CAUTION: the reference data here are in kcal/mol for the energies and kcal/mol/A for the forces. The NequIP model will therefore also be predicting outputs in these units. We are therefore using `units real` in LAMMPS (see [docs](https://docs.lammps.org/units.html)). If your reference data are in other units, you should using the corresponding units command in LAMMPS (e.g. if you use eV, A then `units metal` would be appropriate, which would then also change time units from `fs` to `ps`)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "W090KfMsd2Do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tAHO8ODrpwG"
      },
      "source": [
        "lammps_input_minimize = \"\"\"\n",
        "units\treal\n",
        "atom_style atomic\n",
        "newton off\n",
        "thermo 1\n",
        "read_data structure.data\n",
        "\n",
        "pair_style\tnequip\n",
        "pair_coeff\t* * ../toluene-deployed.pth C H\n",
        "mass            1 15.9994\n",
        "mass            2 1.00794\n",
        "\n",
        "neighbor 1.0 bin\n",
        "neigh_modify delay 5 every 1\n",
        "\n",
        "minimize 0.0 1.0e-8 10000 1000000\n",
        "write_dump all custom output.dump id type x y z fx fy fz\n",
        "\"\"\"\n",
        "!mkdir lammps_run\n",
        "with open(\"lammps_run/toluene_minimize.in\", \"w\") as f:\n",
        "    f.write(lammps_input_minimize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvWZCw1zvjRc"
      },
      "source": [
        "Here's starting configuration for Toluene at CCSD(T) accuracy. We will strongly perturb the inital positions by sampling from a uniform distribution $\\mathcal{U}([0, 0.5])$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEPfMeGnJUVH"
      },
      "source": [
        "toluene_example = \"\"\"15\n",
        " Lattice=\"100.0 0.0 0.0 0.0 100.0 0.0 0.0 0.0 100.0\" Properties=species:S:1:pos:R:3 -169777.5840406276=T pbc=\"F F F\"\n",
        " C       52.48936904      49.86911725      50.09520748\n",
        " C       51.01088202      49.89609925      50.17978049\n",
        " C       50.36647401      50.04650925      48.96054247\n",
        " C       48.95673398      50.29576626      48.71580846\n",
        " C       48.04533296      50.26023426      49.82589448\n",
        " C       48.70932398      49.85770925      51.01923950\n",
        " C       50.06326400      49.77782925      51.25691751\n",
        " H       52.94467905      50.48672926      50.86545150\n",
        " H       52.89060405      48.87175023      50.14480949\n",
        " H       53.02173405      50.05890725      49.03968247\n",
        " H       51.01439802      50.38234726      48.05314045\n",
        " H       48.80598498      50.64314926      47.68195744\n",
        " H       46.96754695      50.20586626      49.53998848\n",
        " H       48.16716997      49.75850325      51.88622952\n",
        " H       50.45791001      49.55387424      52.15303052\n",
        " \"\"\"\n",
        "\n",
        "with open('toluene.xyz', 'w') as f:\n",
        "    f.write(toluene_example)\n",
        "\n",
        "# read as ASE objects\n",
        "atoms = read('toluene.xyz', format='extxyz')\n",
        "\n",
        "# perturb positions\n",
        "p = atoms.get_positions()\n",
        "p += np.random.rand(15, 3) * 0.5\n",
        "atoms.set_positions(p)\n",
        "atoms.set_pbc(False)\n",
        "\n",
        "# write to a LAMMPS file\n",
        "write(\"lammps_run/structure.data\", atoms, format=\"lammps-data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDuyueY11YBF"
      },
      "source": [
        "### Run the LAMMPS command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gurLjNK5upvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13e735a0-ea9a-4108-c0a8-c5ea6bb1de6b"
      },
      "source": [
        "!cd lammps_run/ && ../lammps/build/lmp -in toluene_minimize.in"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LAMMPS (29 Sep 2021 - Update 2)\n",
            "OMP_NUM_THREADS environment is not set. Defaulting to 1 thread. (src/comm.cpp:98)\n",
            "  using 1 OpenMP thread(s) per MPI task\n",
            "Reading data file ...\n",
            "  orthogonal box = (0.0000000 0.0000000 0.0000000) to (100.00000 100.00000 100.00000)\n",
            "  1 by 1 by 1 MPI processor grid\n",
            "  reading atoms ...\n",
            "  15 atoms\n",
            "  read_data CPU = 0.002 seconds\n",
            "NEQUIP is using device cuda\n",
            "NequIP Coeff: type 1 is element C\n",
            "NequIP Coeff: type 2 is element H\n",
            "Loading model from ../toluene-deployed.pth\n",
            "Freezing TorchScript model...\n",
            "WARNING: Using 'neigh_modify every 1 delay 0 check yes' setting during minimization (src/min.cpp:188)\n",
            "Neighbor list info ...\n",
            "  update every 1 steps, delay 0 steps, check yes\n",
            "  max neighbors/atom: 2000, page size: 100000\n",
            "  master list distance cutoff = 5\n",
            "  ghost atom cutoff = 5\n",
            "  binsize = 2.5, bins = 40 40 40\n",
            "  1 neighbor lists, perpetual/occasional/extra = 1 0 0\n",
            "  (1) pair nequip, perpetual\n",
            "      attributes: full, newton off, ghost\n",
            "      pair build: full/bin/ghost\n",
            "      stencil: full/ghost/bin/3d\n",
            "      bin: standard\n",
            "Setting up cg style minimization ...\n",
            "  Unit style    : real\n",
            "  Current step  : 0\n",
            "Per MPI rank memory allocation (min/avg/max) = 4.603 | 4.603 | 4.603 Mbytes\n",
            "Step Temp E_pair E_mol TotEng Press \n",
            "       0            0   -169569.11            0   -169569.11            0 \n",
            "       1            0   -169648.28            0   -169648.28            0 \n",
            "       2            0   -169719.86            0   -169719.86            0 \n",
            "       3            0    -169769.8            0    -169769.8            0 \n",
            "       4            0   -169792.31            0   -169792.31            0 \n",
            "       5            0   -169803.03            0   -169803.03            0 \n",
            "       6            0   -169806.83            0   -169806.83            0 \n",
            "       7            0   -169810.16            0   -169810.16            0 \n",
            "       8            0   -169812.75            0   -169812.75            0 \n",
            "       9            0   -169813.66            0   -169813.66            0 \n",
            "      10            0    -169814.3            0    -169814.3            0 \n",
            "      11            0   -169814.77            0   -169814.77            0 \n",
            "      12            0   -169815.05            0   -169815.05            0 \n",
            "      13            0   -169815.28            0   -169815.28            0 \n",
            "      14            0    -169815.7            0    -169815.7            0 \n",
            "      15            0   -169815.88            0   -169815.88            0 \n",
            "      16            0   -169816.05            0   -169816.05            0 \n",
            "      17            0   -169816.23            0   -169816.23            0 \n",
            "      18            0   -169816.31            0   -169816.31            0 \n",
            "      19            0   -169816.36            0   -169816.36            0 \n",
            "      20            0   -169816.42            0   -169816.42            0 \n",
            "      21            0   -169816.44            0   -169816.44            0 \n",
            "      22            0   -169816.47            0   -169816.47            0 \n",
            "      23            0   -169816.52            0   -169816.52            0 \n",
            "      24            0   -169816.52            0   -169816.52            0 \n",
            "      25            0   -169816.52            0   -169816.52            0 \n",
            "      26            0   -169816.52            0   -169816.52            0 \n",
            "      27            0   -169816.52            0   -169816.52            0 \n",
            "      28            0   -169816.52            0   -169816.52            0 \n",
            "      29            0   -169816.53            0   -169816.53            0 \n",
            "      30            0   -169816.55            0   -169816.55            0 \n",
            "      31            0   -169816.55            0   -169816.55            0 \n",
            "      32            0   -169816.56            0   -169816.56            0 \n",
            "      33            0   -169816.56            0   -169816.56            0 \n",
            "Loop time of 11.5642 on 1 procs for 33 steps with 15 atoms\n",
            "\n",
            "98.9% CPU use with 1 MPI tasks x 1 OpenMP threads\n",
            "\n",
            "Minimization stats:\n",
            "  Stopping criterion = linesearch alpha is zero\n",
            "  Energy initial, next-to-last, final = \n",
            "        -169569.109375       -169816.5625       -169816.5625\n",
            "  Force two-norm initial, final = 485.27448 2.6820958\n",
            "  Force max component initial, final = 212.56668 1.0711311\n",
            "  Final line search alpha, max atom move = 1.3603356e-09 1.4570978e-09\n",
            "  Iterations, force evaluations = 33 119\n",
            "\n",
            "MPI task timing breakdown:\n",
            "Section |  min time  |  avg time  |  max time  |%varavg| %total\n",
            "---------------------------------------------------------------\n",
            "Pair    | 11.562     | 11.562     | 11.562     |   0.0 | 99.98\n",
            "Neigh   | 9.3531e-05 | 9.3531e-05 | 9.3531e-05 |   0.0 |  0.00\n",
            "Comm    | 5.6191e-05 | 5.6191e-05 | 5.6191e-05 |   0.0 |  0.00\n",
            "Output  | 0.00098602 | 0.00098602 | 0.00098602 |   0.0 |  0.01\n",
            "Modify  | 0          | 0          | 0          |   0.0 |  0.00\n",
            "Other   |            | 0.0006101  |            |       |  0.01\n",
            "\n",
            "Nlocal:        15.0000 ave          15 max          15 min\n",
            "Histogram: 1 0 0 0 0 0 0 0 0 0\n",
            "Nghost:         0.00000 ave           0 max           0 min\n",
            "Histogram: 1 0 0 0 0 0 0 0 0 0\n",
            "Neighs:         0.00000 ave           0 max           0 min\n",
            "Histogram: 1 0 0 0 0 0 0 0 0 0\n",
            "FullNghs:      190.000 ave         190 max         190 min\n",
            "Histogram: 1 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "Total # of neighbors = 190\n",
            "Ave neighs/atom = 12.666667\n",
            "Neighbor list builds = 1\n",
            "Dangerous builds = 0\n",
            "Total wall time: 0:00:16\n",
            "[6bc2016184fb:03199] *** Process received signal ***\n",
            "[6bc2016184fb:03199] Signal: Segmentation fault (11)\n",
            "[6bc2016184fb:03199] Signal code: Address not mapped (1)\n",
            "[6bc2016184fb:03199] Failing at address: 0x7f331cd2820d\n",
            "[6bc2016184fb:03199] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980)[0x7f331f9d3980]\n",
            "[6bc2016184fb:03199] [ 1] /lib/x86_64-linux-gnu/libc.so.6(getenv+0xa5)[0x7f331f6128a5]\n",
            "[6bc2016184fb:03199] [ 2] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(_ZN13TCMallocGuardD1Ev+0x34)[0x7f331fe7de44]\n",
            "[6bc2016184fb:03199] [ 3] /lib/x86_64-linux-gnu/libc.so.6(__cxa_finalize+0xf5)[0x7f331f613735]\n",
            "[6bc2016184fb:03199] [ 4] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(+0x13cb3)[0x7f331fe7bcb3]\n",
            "[6bc2016184fb:03199] *** End of error message ***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOKfQ83JQESc"
      },
      "source": [
        "We see LAMMPS converges quickly to a minimum. Let's check how well we did."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPcQU9HbsaVl"
      },
      "source": [
        "# read the final structure back in\n",
        "minimized = read('./lammps_run/output.dump', format='lammps-dump-text')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brqGqVtdWpCF"
      },
      "source": [
        "### Compare optimized bond length to true coupled cluster reference from CCCBDB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltFlaHrTRn97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c6a131b-01a5-4b39-b972-945508bb7c6d"
      },
      "source": [
        "# get distances of optimized geometry (reference data: CCSD(T) [Psi4, cc-pVDZ])\n",
        "d_12 = minimized.get_distances(1, 2)\n",
        "\n",
        "# reference: https://cccbdb.nist.gov/geom3x.asp?method=6&basis=2, coupled cluster\n",
        "d_12_ccd = 1.4086\n",
        "\n",
        "print('Relative Error in bond length w.r.t. Coupled Cluster from CCCBDB: {:.3f}%'.format((100 * np.abs(d_12 - d_12_ccd) / d_12_ccd)[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relative Error in bond length w.r.t. Coupled Cluster from CCCBDB: 0.100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT64gDUeQOvO"
      },
      "source": [
        "We find a final relative error close to Coupled Cluster accuracy üéâ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4ZD6U0EkIp5"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "This concludes our tutorial. A next step would be to head over to https://github.com/mir-group/nequip, install NequIP and get started with your own system. If you have questions, please don't hesitate to reach out to batzner@g.harvard.edu, we're happy to help!\n",
        "\n"
      ]
    }
  ]
}